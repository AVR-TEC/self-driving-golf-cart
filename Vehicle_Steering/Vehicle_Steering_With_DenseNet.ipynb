{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Steering with DenseNet Architecture\n",
    "In this notebook, we will talk through training vechicle steering with Udacity data with a newly proposed architecture called DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import steering_img_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset\n",
    "thanks to the Udacity open course dataset, we can train a preliminary model with the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/home/ubuntu/rosbags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165831, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>frame_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>angle</th>\n",
       "      <th>torque</th>\n",
       "      <th>speed</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>alt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-11-17 22:23:03.137449833</td>\n",
       "      <td>1479421383137449833</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "      <td>center_camera</td>\n",
       "      <td>center/1479421383137449833.jpg</td>\n",
       "      <td>-0.098579</td>\n",
       "      <td>-0.659684</td>\n",
       "      <td>14.954319</td>\n",
       "      <td>37.401958</td>\n",
       "      <td>-122.114761</td>\n",
       "      <td>-6.791021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-11-17 22:23:03.176826139</td>\n",
       "      <td>1479421383176826139</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "      <td>left_camera</td>\n",
       "      <td>left/1479421383176826139.jpg</td>\n",
       "      <td>-0.095147</td>\n",
       "      <td>-0.316359</td>\n",
       "      <td>14.976260</td>\n",
       "      <td>37.401962</td>\n",
       "      <td>-122.114769</td>\n",
       "      <td>-6.783799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-11-17 22:23:03.178356639</td>\n",
       "      <td>1479421383178356639</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "      <td>right_camera</td>\n",
       "      <td>right/1479421383178356639.jpg</td>\n",
       "      <td>-0.095014</td>\n",
       "      <td>-0.297284</td>\n",
       "      <td>14.976896</td>\n",
       "      <td>37.401962</td>\n",
       "      <td>-122.114769</td>\n",
       "      <td>-6.783934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-11-17 22:23:03.187204276</td>\n",
       "      <td>1479421383187204276</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "      <td>center_camera</td>\n",
       "      <td>center/1479421383187204276.jpg</td>\n",
       "      <td>-0.094241</td>\n",
       "      <td>-0.187620</td>\n",
       "      <td>14.980588</td>\n",
       "      <td>37.401962</td>\n",
       "      <td>-122.114769</td>\n",
       "      <td>-6.784318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-11-17 22:23:03.226476487</td>\n",
       "      <td>1479421383226476487</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "      <td>left_camera</td>\n",
       "      <td>left/1479421383226476487.jpg</td>\n",
       "      <td>-0.089075</td>\n",
       "      <td>-0.189749</td>\n",
       "      <td>15.005255</td>\n",
       "      <td>37.401966</td>\n",
       "      <td>-122.114777</td>\n",
       "      <td>-6.775640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           index            timestamp  width  height  \\\n",
       "0  2016-11-17 22:23:03.137449833  1479421383137449833    640     480   \n",
       "1  2016-11-17 22:23:03.176826139  1479421383176826139    640     480   \n",
       "2  2016-11-17 22:23:03.178356639  1479421383178356639    640     480   \n",
       "3  2016-11-17 22:23:03.187204276  1479421383187204276    640     480   \n",
       "4  2016-11-17 22:23:03.226476487  1479421383226476487    640     480   \n",
       "\n",
       "        frame_id                        filename     angle    torque  \\\n",
       "0  center_camera  center/1479421383137449833.jpg -0.098579 -0.659684   \n",
       "1    left_camera    left/1479421383176826139.jpg -0.095147 -0.316359   \n",
       "2   right_camera   right/1479421383178356639.jpg -0.095014 -0.297284   \n",
       "3  center_camera  center/1479421383187204276.jpg -0.094241 -0.187620   \n",
       "4    left_camera    left/1479421383226476487.jpg -0.089075 -0.189749   \n",
       "\n",
       "       speed        lat        long       alt  \n",
       "0  14.954319  37.401958 -122.114761 -6.791021  \n",
       "1  14.976260  37.401962 -122.114769 -6.783799  \n",
       "2  14.976896  37.401962 -122.114769 -6.783934  \n",
       "3  14.980588  37.401962 -122.114769 -6.784318  \n",
       "4  15.005255  37.401966 -122.114777 -6.775640  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steering_labels = pd.read_csv(\"interpolated.csv\")\n",
    "print(steering_labels.shape)\n",
    "steering_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for i in range(5000):\n",
    "    file_name = steering_labels.iloc[i][\"filename\"]\n",
    "    img = cv2.imread(file_name)\n",
    "    f = float(steering_labels.iloc[i][\"angle\"])\n",
    "    x.append(img)\n",
    "    y.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(arr):\n",
    "    num = len(arr)\n",
    "    while True:\n",
    "        shuffle(arr)\n",
    "        for i in range(0, num, batch_size):\n",
    "            batch_lines = arr[i:i + batch_size]\n",
    "\n",
    "            images = []\n",
    "            steerings = []\n",
    "            for line in batch_lines:\n",
    "                center_path = line[0]\n",
    "                steering = float(line[3])\n",
    "                center_real_path = path_prefix + center_path\n",
    "                image = cv2.imread(center_real_path)\n",
    "                #image = cv2.imread(center_path)\n",
    "                images.append(image)\n",
    "                steerings.append(steering)\n",
    "\n",
    "                image_flip=np.fliplr(image)\n",
    "                images.append(image_flip)\n",
    "                steerings.append(-steering)\n",
    "\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(steerings)\n",
    "\n",
    "            yield shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image augmentation and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will standardize the images and change its "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "\n",
    "#     img = img_util.get_image_name(steering_labels, i, augmentation=False, trans_range=0, scale_range=0)\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "#     print(steering_labels.iloc[i][\"angle\"])\n",
    "#     print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Merge\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import AveragePooling2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(ip, nb_filter, bottleneck=False, dropout_rate=None, weight_decay=1e-4):\n",
    "    ''' Apply BatchNorm, Relu, 3x3 Conv2D, optional bottleneck block and dropout\n",
    "    Args:\n",
    "        ip: Input keras tensor\n",
    "        nb_filter: number of filters\n",
    "        bottleneck: add bottleneck block\n",
    "        dropout_rate: dropout rate\n",
    "        weight_decay: weight decay factor\n",
    "    Returns: keras tensor with batch_norm, relu and convolution2d added (optional bottleneck)\n",
    "    '''\n",
    "    concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(ip)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    if bottleneck:\n",
    "        inter_channel = nb_filter * 4  # Obtained from https://github.com/liuzhuang13/DenseNet/blob/master/densenet.lua\n",
    "\n",
    "        x = Convolution2D(inter_channel, (1, 1), kernel_initializer='he_normal', padding='same', use_bias=False,\n",
    "                   kernel_regularizer=l2(weight_decay))(x)\n",
    "        x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "    x = Convolution2D(nb_filter, (3, 3), kernel_initializer='he_normal', padding='same', use_bias=False)(x)\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def dense_block(x, nb_layers, nb_filter, growth_rate, bottleneck=False, dropout_rate=None, weight_decay=1e-4,\n",
    "                  grow_nb_filters=True, return_concat_list=False):\n",
    "    ''' Build a dense_block where the output of each conv_block is fed to subsequent ones\n",
    "    Args:\n",
    "        x: keras tensor\n",
    "        nb_layers: the number of layers of conv_block to append to the model.\n",
    "        nb_filter: number of filters\n",
    "        growth_rate: growth rate\n",
    "        bottleneck: bottleneck block\n",
    "        dropout_rate: dropout rate\n",
    "        weight_decay: weight decay factor\n",
    "        grow_nb_filters: flag to decide to allow number of filters to grow\n",
    "        return_concat_list: return the list of feature maps along with the actual output\n",
    "    Returns: keras tensor with nb_layers of conv_block appended\n",
    "    '''\n",
    "    concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    x_list = [x]\n",
    "\n",
    "    for i in range(nb_layers):\n",
    "        cb = conv_block(x, growth_rate, bottleneck, dropout_rate, weight_decay)\n",
    "        x_list.append(cb)\n",
    "\n",
    "        x = concatenate([x, cb], axis=concat_axis)\n",
    "\n",
    "        if grow_nb_filters:\n",
    "            nb_filter += growth_rate\n",
    "\n",
    "    if return_concat_list:\n",
    "        return x, nb_filter, x_list\n",
    "    else:\n",
    "        return x, nb_filter\n",
    "\n",
    "\n",
    "def transition_block(ip, nb_filter, compression=1.0, weight_decay=1e-4):\n",
    "    ''' Apply BatchNorm, Relu 1x1, Conv2D, optional compression, dropout and Maxpooling2D\n",
    "    Args:\n",
    "        ip: keras tensor\n",
    "        nb_filter: number of filters\n",
    "        compression: calculated as 1 - reduction. Reduces the number of feature maps\n",
    "                    in the transition block.\n",
    "        dropout_rate: dropout rate\n",
    "        weight_decay: weight decay factor\n",
    "    Returns: keras tensor, after applying batch_norm, relu-conv, dropout, maxpool\n",
    "    '''\n",
    "    concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(ip)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(int(nb_filter * compression), (1, 1), kernel_initializer='he_normal', padding='same', use_bias=False,\n",
    "               kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = AveragePooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def create_dense_net(nb_classes, img_input, depth=40, nb_dense_block=3, growth_rate=12, nb_filter=-1,\n",
    "                       nb_layers_per_block=-1, bottleneck=False, dropout_rate=None, weight_decay=1e-4, activation='softmax', compression=1.0):\n",
    "    ''' Build the DenseNet model\n",
    "    Args:\n",
    "        nb_classes: number of classes\n",
    "        img_input: tuple of shape (channels, rows, columns) or (rows, columns, channels)\n",
    "        include_top: flag to include the final Dense layer\n",
    "        depth: number or layers\n",
    "        nb_dense_block: number of dense blocks to add to end (generally = 3)\n",
    "        growth_rate: number of filters to add per dense block\n",
    "        nb_filter: initial number of filters. Default -1 indicates initial number of filters is 2 * growth_rate\n",
    "        nb_layers_per_block: number of layers in each dense block.\n",
    "                Can be a -1, positive integer or a list.\n",
    "                If -1, calculates nb_layer_per_block from the depth of the network.\n",
    "                If positive integer, a set number of layers per dense block.\n",
    "                If list, nb_layer is used as provided. Note that list size must\n",
    "                be (nb_dense_block + 1)\n",
    "        bottleneck: add bottleneck blocks\n",
    "        reduction: reduction factor of transition blocks. Note : reduction value is inverted to compute compression\n",
    "        dropout_rate: dropout rate\n",
    "        weight_decay: weight decay rate\n",
    "        subsample_initial_block: Set to True to subsample the initial convolution and\n",
    "                add a MaxPool2D before the dense blocks are added.\n",
    "        subsample_initial:\n",
    "        activation: Type of activation at the top layer. Can be one of 'softmax' or 'sigmoid'.\n",
    "                Note that if sigmoid is used, classes must be 1.\n",
    "    Returns: keras tensor with nb_layers of conv_block appended\n",
    "    '''\n",
    "\n",
    "    concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    # layers in each dense block\n",
    "    if type(nb_layers_per_block) is list or type(nb_layers_per_block) is tuple:\n",
    "        nb_layers = list(nb_layers_per_block)  # Convert tuple to list\n",
    "\n",
    "        assert len(nb_layers) == (nb_dense_block), 'If list, nb_layer is used as provided. ' \\\n",
    "                                                   'Note that list size must be (nb_dense_block)'\n",
    "        final_nb_layer = nb_layers[-1]\n",
    "        nb_layers = nb_layers[:-1]\n",
    "    else:\n",
    "        if nb_layers_per_block == -1:\n",
    "            assert (depth - 4) % 3 == 0, 'Depth must be 3 N + 4 if nb_layers_per_block == -1'\n",
    "            count = int((depth - 4) / 3)\n",
    "            nb_layers = [count for _ in range(nb_dense_block)]\n",
    "            final_nb_layer = count\n",
    "        else:\n",
    "            final_nb_layer = nb_layers_per_block\n",
    "            nb_layers = [nb_layers_per_block] * nb_dense_block\n",
    "\n",
    "    initial_kernel = (3, 3)\n",
    "    initial_strides = (1, 1)\n",
    "\n",
    "    x = Convolution2D(nb_filter, initial_kernel, kernel_initializer='he_normal', padding='same',\n",
    "               strides=initial_strides, use_bias=False, kernel_regularizer=l2(weight_decay))(img_input)\n",
    "\n",
    "    # Add dense blocks\n",
    "    for block_idx in range(nb_dense_block - 1):\n",
    "        x, nb_filter = dense_block(x, nb_layers[block_idx], nb_filter, growth_rate, bottleneck=bottleneck,\n",
    "                                     dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "        # add transition_block\n",
    "        x = transition_block(x, nb_filter, compression=compression, weight_decay=weight_decay)\n",
    "        nb_filter = int(nb_filter * compression)\n",
    "\n",
    "    # The last dense_block does not have a transition_block\n",
    "    x, nb_filter = dense_block(x, final_nb_layer, nb_filter, growth_rate, bottleneck=bottleneck,\n",
    "                                 dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "\n",
    "    x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    x = Dense(nb_classes, activation=activation)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DenseNet(input_shape=None, depth=40, nb_dense_block=5, growth_rate=12, nb_filter=32, nb_layers_per_block=-1,\n",
    "             bottleneck=False, dropout_rate=0.0, weight_decay=1e-4, classes=10, activation='softmax'):\n",
    "    \n",
    "    '''Note that when using TensorFlow,\n",
    "        for best performance you should set\n",
    "        `image_data_format='channels_last'` in your Keras config\n",
    "        at ~/.keras/keras.json.\n",
    "        The model and the weights are compatible with both TensorFlow and Theano. The dimension ordering\n",
    "        convention used by the model is the one specified in your Keras config file.\n",
    "        # Arguments\n",
    "            input_shape: optional shape tuple, only to be specified\n",
    "                if `include_top` is False (otherwise the input shape\n",
    "                has to be `(32, 32, 3)` (with `channels_last` dim ordering)\n",
    "                or `(3, 32, 32)` (with `channels_first` dim ordering).\n",
    "                It should have exactly 3 inputs channels,\n",
    "                and width and height should be no smaller than 8.\n",
    "                E.g. `(200, 200, 3)` would be one valid value.\n",
    "            depth: number or layers in the DenseNet\n",
    "            nb_dense_block: number of dense blocks to add to end (generally = 3)\n",
    "            growth_rate: number of filters to add per dense block\n",
    "            nb_filter: initial number of filters. -1 indicates initial\n",
    "                number of filters is 2 * growth_rate\n",
    "            nb_layers_per_block: number of layers in each dense block.\n",
    "                Can be a -1, positive integer or a list.\n",
    "                If -1, calculates nb_layer_per_block from the network depth.\n",
    "                If positive integer, a set number of layers per dense block.\n",
    "                If list, nb_layer is used as provided. Note that list size must\n",
    "                be (nb_dense_block + 1)\n",
    "            bottleneck: flag to add bottleneck blocks in between dense blocks\n",
    "            reduction: reduction factor of transition blocks.\n",
    "                Note : reduction value is inverted to compute compression.\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay rate\n",
    "            classes: optional number of classes to classify images\n",
    "                into, only to be specified if `include_top` is True, and\n",
    "                if no `weights` argument is specified.\n",
    "            activation: Type of activation at the top layer. Can be one of 'softmax' or 'sigmoid'.\n",
    "                Note that if sigmoid is used, classes must be 1.\n",
    "        # Returns\n",
    "            A Keras model instance.\n",
    "        '''\n",
    "    model_input = Input(shape=img_dim)\n",
    "    x = create_dense_net(classes, model_input, depth, nb_dense_block,\n",
    "                           growth_rate, nb_filter, nb_layers_per_block, bottleneck,\n",
    "                           dropout_rate, weight_decay, activation)\n",
    "\n",
    "\n",
    "    # Create model.\n",
    "    model = Model(model_input, x, name='densenet')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dim = (480, 640, 3)\n",
    "nb_classes = 1\n",
    "depth = 34\n",
    "nb_dense_blocks = 5\n",
    "nb_filter = 32\n",
    "weight_decay = 1E-4\n",
    "growth_rate = 1\n",
    "dropout_rate = None\n",
    "model = DenseNet(img_dim, depth, nb_dense_blocks, growth_rate, bottleneck = True, classes = 1, nb_layers_per_block=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 480, 640, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 480, 640, 32)  864         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 480, 640, 32)  128         conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 480, 640, 32)  0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 480, 640, 4)   128         activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 480, 640, 4)   16          conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 480, 640, 4)   0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 480, 640, 1)   36          activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 480, 640, 33)  0           conv2d_1[0][0]                   \n",
      "                                                                   conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 480, 640, 33)  132         concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 480, 640, 33)  0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 480, 640, 4)   132         activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 480, 640, 4)   16          conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 480, 640, 4)   0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 480, 640, 1)   36          activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 480, 640, 34)  0           concatenate_1[0][0]              \n",
      "                                                                   conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 480, 640, 34)  136         concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 480, 640, 34)  0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 480, 640, 4)   136         activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 480, 640, 4)   16          conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 480, 640, 4)   0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 480, 640, 1)   36          activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 480, 640, 35)  0           concatenate_2[0][0]              \n",
      "                                                                   conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 480, 640, 35)  140         concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 480, 640, 35)  0           batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 480, 640, 4)   140         activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 480, 640, 4)   16          conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 480, 640, 4)   0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 480, 640, 1)   36          activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 480, 640, 36)  0           concatenate_3[0][0]              \n",
      "                                                                   conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 480, 640, 36)  144         concatenate_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 480, 640, 36)  0           batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 480, 640, 36)  1296        activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePool (None, 240, 320, 36)  0           conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, 240, 320, 36)  144         average_pooling2d_1[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 240, 320, 36)  0           batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 240, 320, 4)   144         activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, 240, 320, 4)   16          conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 240, 320, 4)   0           batch_normalization_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 240, 320, 1)   36          activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 240, 320, 37)  0           average_pooling2d_1[0][0]        \n",
      "                                                                   conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, 240, 320, 37)  148         concatenate_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 240, 320, 37)  0           batch_normalization_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, 240, 320, 4)   148         activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, 240, 320, 4)   16          conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 240, 320, 4)   0           batch_normalization_13[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, 240, 320, 1)   36          activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)      (None, 240, 320, 38)  0           concatenate_5[0][0]              \n",
      "                                                                   conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, 240, 320, 38)  152         concatenate_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 240, 320, 38)  0           batch_normalization_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, 240, 320, 4)   152         activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNor (None, 240, 320, 4)   16          conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 240, 320, 4)   0           batch_normalization_15[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, 240, 320, 1)   36          activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)      (None, 240, 320, 39)  0           concatenate_6[0][0]              \n",
      "                                                                   conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNor (None, 240, 320, 39)  156         concatenate_7[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 240, 320, 39)  0           batch_normalization_16[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, 240, 320, 4)   156         activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNor (None, 240, 320, 4)   16          conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 240, 320, 4)   0           batch_normalization_17[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, 240, 320, 1)   36          activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)      (None, 240, 320, 40)  0           concatenate_7[0][0]              \n",
      "                                                                   conv2d_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNor (None, 240, 320, 40)  160         concatenate_8[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 240, 320, 40)  0           batch_normalization_18[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, 240, 320, 40)  1600        activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePool (None, 120, 160, 40)  0           conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, 120, 160, 40)  160         average_pooling2d_2[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 120, 160, 40)  0           batch_normalization_19[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, 120, 160, 4)   160         activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNor (None, 120, 160, 4)   16          conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 120, 160, 4)   0           batch_normalization_20[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, 120, 160, 1)   36          activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)      (None, 120, 160, 41)  0           average_pooling2d_2[0][0]        \n",
      "                                                                   conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNor (None, 120, 160, 41)  164         concatenate_9[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 120, 160, 41)  0           batch_normalization_21[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, 120, 160, 4)   164         activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNor (None, 120, 160, 4)   16          conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 120, 160, 4)   0           batch_normalization_22[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, 120, 160, 1)   36          activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)     (None, 120, 160, 42)  0           concatenate_9[0][0]              \n",
      "                                                                   conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNor (None, 120, 160, 42)  168         concatenate_10[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 120, 160, 42)  0           batch_normalization_23[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, 120, 160, 4)   168         activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNor (None, 120, 160, 4)   16          conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 120, 160, 4)   0           batch_normalization_24[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, 120, 160, 1)   36          activation_24[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)     (None, 120, 160, 43)  0           concatenate_10[0][0]             \n",
      "                                                                   conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNor (None, 120, 160, 43)  172         concatenate_11[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 120, 160, 43)  0           batch_normalization_25[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, 120, 160, 4)   172         activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNor (None, 120, 160, 4)   16          conv2d_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 120, 160, 4)   0           batch_normalization_26[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)               (None, 120, 160, 1)   36          activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)     (None, 120, 160, 44)  0           concatenate_11[0][0]             \n",
      "                                                                   conv2d_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNor (None, 120, 160, 44)  176         concatenate_12[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 120, 160, 44)  0           batch_normalization_27[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)               (None, 120, 160, 44)  1936        activation_27[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePool (None, 60, 80, 44)    0           conv2d_28[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNor (None, 60, 80, 44)    176         average_pooling2d_3[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, 60, 80, 44)    0           batch_normalization_28[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)               (None, 60, 80, 4)     176         activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNor (None, 60, 80, 4)     16          conv2d_29[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_29 (Activation)       (None, 60, 80, 4)     0           batch_normalization_29[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)               (None, 60, 80, 1)     36          activation_29[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)     (None, 60, 80, 45)    0           average_pooling2d_3[0][0]        \n",
      "                                                                   conv2d_30[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNor (None, 60, 80, 45)    180         concatenate_13[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_30 (Activation)       (None, 60, 80, 45)    0           batch_normalization_30[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)               (None, 60, 80, 4)     180         activation_30[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNor (None, 60, 80, 4)     16          conv2d_31[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_31 (Activation)       (None, 60, 80, 4)     0           batch_normalization_31[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)               (None, 60, 80, 1)     36          activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)     (None, 60, 80, 46)    0           concatenate_13[0][0]             \n",
      "                                                                   conv2d_32[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNor (None, 60, 80, 46)    184         concatenate_14[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, 60, 80, 46)    0           batch_normalization_32[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)               (None, 60, 80, 4)     184         activation_32[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNor (None, 60, 80, 4)     16          conv2d_33[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_33 (Activation)       (None, 60, 80, 4)     0           batch_normalization_33[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)               (None, 60, 80, 1)     36          activation_33[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)     (None, 60, 80, 47)    0           concatenate_14[0][0]             \n",
      "                                                                   conv2d_34[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNor (None, 60, 80, 47)    188         concatenate_15[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_34 (Activation)       (None, 60, 80, 47)    0           batch_normalization_34[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)               (None, 60, 80, 4)     188         activation_34[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNor (None, 60, 80, 4)     16          conv2d_35[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_35 (Activation)       (None, 60, 80, 4)     0           batch_normalization_35[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)               (None, 60, 80, 1)     36          activation_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)     (None, 60, 80, 48)    0           concatenate_15[0][0]             \n",
      "                                                                   conv2d_36[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNor (None, 60, 80, 48)    192         concatenate_16[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_36 (Activation)       (None, 60, 80, 48)    0           batch_normalization_36[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)               (None, 60, 80, 48)    2304        activation_36[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePool (None, 30, 40, 48)    0           conv2d_37[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNor (None, 30, 40, 48)    192         average_pooling2d_4[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_37 (Activation)       (None, 30, 40, 48)    0           batch_normalization_37[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)               (None, 30, 40, 4)     192         activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNor (None, 30, 40, 4)     16          conv2d_38[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_38 (Activation)       (None, 30, 40, 4)     0           batch_normalization_38[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)               (None, 30, 40, 1)     36          activation_38[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)     (None, 30, 40, 49)    0           average_pooling2d_4[0][0]        \n",
      "                                                                   conv2d_39[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNor (None, 30, 40, 49)    196         concatenate_17[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_39 (Activation)       (None, 30, 40, 49)    0           batch_normalization_39[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)               (None, 30, 40, 4)     196         activation_39[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNor (None, 30, 40, 4)     16          conv2d_40[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_40 (Activation)       (None, 30, 40, 4)     0           batch_normalization_40[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)               (None, 30, 40, 1)     36          activation_40[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)     (None, 30, 40, 50)    0           concatenate_17[0][0]             \n",
      "                                                                   conv2d_41[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNor (None, 30, 40, 50)    200         concatenate_18[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_41 (Activation)       (None, 30, 40, 50)    0           batch_normalization_41[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)               (None, 30, 40, 4)     200         activation_41[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNor (None, 30, 40, 4)     16          conv2d_42[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_42 (Activation)       (None, 30, 40, 4)     0           batch_normalization_42[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)               (None, 30, 40, 1)     36          activation_42[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)     (None, 30, 40, 51)    0           concatenate_18[0][0]             \n",
      "                                                                   conv2d_43[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNor (None, 30, 40, 51)    204         concatenate_19[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_43 (Activation)       (None, 30, 40, 51)    0           batch_normalization_43[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)               (None, 30, 40, 4)     204         activation_43[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNor (None, 30, 40, 4)     16          conv2d_44[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_44 (Activation)       (None, 30, 40, 4)     0           batch_normalization_44[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)               (None, 30, 40, 1)     36          activation_44[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)     (None, 30, 40, 52)    0           concatenate_19[0][0]             \n",
      "                                                                   conv2d_45[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNor (None, 30, 40, 52)    208         concatenate_20[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_45 (Activation)       (None, 30, 40, 52)    0           batch_normalization_45[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glob (None, 52)            0           activation_45[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             53          global_average_pooling2d_1[0][0] \n",
      "====================================================================================================\n",
      "Total params: 16,613\n",
      "Trainable params: 14,353\n",
      "Non-trainable params: 2,260\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_train_batch(data,batch_size = 32):\n",
    "      ##### Image size,\n",
    "    img_rows = 480\n",
    "    img_cols = 640\n",
    "    \n",
    "    batch_images = np.zeros((batch_size, img_rows, img_cols, 3))\n",
    "    angles = np.zeros((batch_size, 1))\n",
    "    while 1:\n",
    "        for i_batch in range(batch_size):\n",
    "            i_line = np.random.randint(2000)\n",
    "            i_line = i_line+len(data)-2000\n",
    "            \n",
    "            file_name = steering_labels.iloc[i_line][\"filename\"]\n",
    "            img = cv2.imread(file_name)\n",
    "            f = float(steering_labels.iloc[i_line][\"angle\"])\n",
    "    \n",
    "            batch_images[i_batch] = img\n",
    "            angles[i_batch] = f\n",
    "        yield batch_images, angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=1e-3) # Using Adam instead of SGD to speed up training\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "  86/1200 [=>............................] - ETA: 701s - loss: 2.6857"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-49579bd8224d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtraining_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_train_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteering_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1900\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1901\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1902\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1640\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_gen = generate_train_batch(steering_labels, 1)\n",
    "history = model.fit_generator(training_gen, steps_per_epoch=1200, epochs=2, verbose=1, callbacks=None, validation_data=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
