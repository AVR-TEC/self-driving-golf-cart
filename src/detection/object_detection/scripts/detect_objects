#! /usr/bin/env python

# MIT License

# Copyright (c) 2017 Yongyang Nie

# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:

# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.

# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

"""Run a YOLO_v2 style detection model test images."""

import colorsys
import cv2
import random
import numpy as np
from keras import backend as K
from keras.models import load_model
from PIL import Image, ImageFont
from yad2k.models.keras_yolo import yolo_eval, yolo_head

#ros
import rospy
from sensor_msgs.msg import Image
from std_msgs.msg import Float32
from cv_bridge import CvBridge, CvBridgeError
from object_detection.msg import DetectionResult


class ObjectDetector:

    def __init__(self):

        rospy.init_node('object_detection')
        rospy.Subscriber('/cv_camera_node/image_raw', Image, callback=self.image_update_callback, queue_size=5)

        self.current_frame = None
        self.bridge = CvBridge()

        # TODO: Impelement these configs in the launch file
        self.model_path = rospy.get_param("/object_detection/model_path")
        self.classes_path = rospy.get_param("/object_detection/classes_path")
        self.anchors_path = rospy.get_param("/object_detection/anchors_path")
        self.iou_threshold = rospy.get_param("/object_detection/")
        self.score_threshold = rospy.get_param("/object_detection/")
        self.input_height = rospy.get_param("/object_detection/")
        self.input_width = rospy.get_param("/object_detection/")
        assert self.model_path.endswith('.h5'), 'Keras model must be a .h5 file.'

        self.sess = K.get_session()

        with open(self.classes_path) as f:
            class_names = f.readlines()
        self.class_names = [c.strip() for c in class_names]

        with open(self.anchors_path) as f:
            anchors = f.readline()
            anchors = [float(x) for x in anchors.split(',')]
            anchors = np.array(anchors).reshape(-1, 2)

        self.yolo_model = load_model(self.model_path)
        print(self.yolo_model.summary())
        self.model_image_size = self.yolo_model.layers[0].input_shape[1:3]
        rospy.loginfo('{} model, anchors, and classes loaded.'.format(self.model_path))

        # Generate colors for drawing bounding boxes.
        hsv_tuples = [(x / len(class_names), 1., 1.)
                      for x in range(len(class_names))]
        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))
        self.colors = list(
            map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),
                self.colors))
        random.seed(10101)              # Fixed seed for consistent colors across runs.
        random.shuffle(self.colors)     # Shuffle colors to decorrelate adjacent classes.
        random.seed(None)               # Reset seed to default.

        # Generate output tensor targets for filtered bounding boxes.
        yolo_outputs = yolo_head(self.yolo_model.output, anchors, len(class_names))
        self.input_image_shape = K.placeholder(shape=(2,))
        self.boxes, self.scores, self.classes = yolo_eval(
            yolo_outputs,
            self.input_image_shape,
            score_threshold=self.score_threshold,
            iou_threshold=self.iou_threshold)

        # Graphics of stuff
        self.font = ImageFont.truetype(font='./detection/object/font/FiraMono-Medium.otf',
                                       size=np.floor(3e-2 * self.input_height + 0.5).astype('int32'))
        self.thickness = (self.input_width + self.input_height) // 300

        # ----------------------- running ros --------------------------#
        steering_pub = rospy.Publisher('/detection/object/detection_result/', Float32, queue_size=5)
        rate = rospy.Rate(15)

        while not rospy.is_shutdown() and self.current_frame is not None:
            angle = self.detect_object(self.current_frame)
            steering_pub.publish(angle)
            rate.sleep()

        # ----------------------- running ros --------------------------#

    def image_update_callback(self, data):

        try:
            cv_image = self.bridge.imgmsg_to_cv2(data, "bgr8")
        except CvBridgeError as e:
            print(e)

        self.current_frame = cv_image

    def detect_object(self, image):

        image = Image.fromarray(cv2.resize(image, (self.input_width, self.input_height)))

        resized_image = image.resize(
            tuple(reversed(self.model_image_size)), Image.BICUBIC)
        image_data = np.array(resized_image, dtype='float32')

        image_data /= 255.
        image_data = np.expand_dims(image_data, 0)  # Add batch dimension.

        out_boxes, out_scores, out_classes = self.sess.run(
            [self.boxes, self.scores, self.classes],
            feed_dict={
                self.yolo_model.input: image_data,
                self.input_image_shape: [image.size[1], image.size[0]],
                K.learning_phase(): 0
            })

        msg = DetectionResult()

        for i, c in reversed(list(enumerate(out_classes))):

            predicted_class = self.class_names[c]
            box = out_boxes[i]
            score = out_scores[i]

            top, left, bottom, right = box
            top = max(0, np.floor(top + 0.5).astype('int32'))
            left = max(0, np.floor(left + 0.5).astype('int32'))
            bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))
            right = min(image.size[0], np.floor(right + 0.5).astype('int32'))

            # TODO implement ROS message generation

        return out_boxes, out_scores, out_classes

