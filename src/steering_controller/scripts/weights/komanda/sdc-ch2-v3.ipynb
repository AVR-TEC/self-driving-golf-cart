{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "slim = tf.contrib.slim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 10 # this parameter can be changed. TODO try longer sequences if memory is available.\n",
    "BATCH_SIZE = 4 # this parameter can also be changed\n",
    "LEFT_CONTEXT = 5\n",
    "\n",
    "HEIGHT = 480\n",
    "WIDTH = 640\n",
    "CHANNELS = 3\n",
    "\n",
    "RNN_SIZE = 32\n",
    "RNN_PROJ = 32\n",
    "\n",
    "CSV_HEADER = \"index,timestamp,width,height,frame_id,filename,angle,torque,speed,lat,long,alt\".split(\",\")\n",
    "OUTPUTS = CSV_HEADER[-6:-3] # angle,torque,speed\n",
    "OUTPUT_DIM = len(OUTPUTS) # predict all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BatchGenerator(object):\n",
    "    def __init__(self, sequence, seq_len, batch_size):\n",
    "        self.sequence = sequence\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        chunk_size = 1 + (len(sequence) - 1) / batch_size\n",
    "        self.indices = [(i*chunk_size) % len(sequence) for i in range(batch_size)]\n",
    "        \n",
    "    def next(self):\n",
    "        while True:\n",
    "            output = []\n",
    "            for i in range(self.batch_size):\n",
    "                idx = self.indices[i]\n",
    "                left_pad = self.sequence[idx - LEFT_CONTEXT:idx]\n",
    "                if len(left_pad) < LEFT_CONTEXT:\n",
    "                    left_pad = [self.sequence[0]] * (LEFT_CONTEXT - len(left_pad)) + left_pad\n",
    "                assert len(left_pad) == LEFT_CONTEXT\n",
    "                leftover = len(self.sequence) - idx\n",
    "                if leftover >= self.seq_len:\n",
    "                    result = self.sequence[idx:idx + self.seq_len]\n",
    "                else:\n",
    "                    result = self.sequence[idx:] + self.sequence[:self.seq_len - leftover]\n",
    "                assert len(result) == self.seq_len\n",
    "                self.indices[i] = (idx + self.seq_len) % len(self.sequence)\n",
    "                images, targets = zip(*result)\n",
    "                images_left_pad, _ = zip(*left_pad)\n",
    "                output.append((np.stack(images_left_pad + images), np.stack(targets)))\n",
    "            output = zip(*output)\n",
    "            output[0] = np.stack(output[0]) # batch_size x (LEFT_CONTEXT + seq_len)\n",
    "            output[1] = np.stack(output[1]) # batch_size x seq_len x OUTPUT_DIM\n",
    "            return output\n",
    "        \n",
    "def read_csv(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = [ln.strip().split(\",\")[-7:-3] for ln in f.readlines()]\n",
    "        lines = map(lambda x: (x[0], np.float32(x[1:])), lines) # imagefile, outputs\n",
    "        return lines\n",
    "\n",
    "def process_csv(filename, val=5):\n",
    "    sum_f = np.float128([0.0] * OUTPUT_DIM)\n",
    "    sum_sq_f = np.float128([0.0] * OUTPUT_DIM)\n",
    "    lines = read_csv(filename)\n",
    "    # leave val% for validation\n",
    "    train_seq = []\n",
    "    valid_seq = []\n",
    "    cnt = 0\n",
    "    for ln in lines:\n",
    "        if cnt < SEQ_LEN * BATCH_SIZE * (100 - val): \n",
    "            train_seq.append(ln)\n",
    "            sum_f += ln[1]\n",
    "            sum_sq_f += ln[1] * ln[1]\n",
    "        else:\n",
    "            valid_seq.append(ln)\n",
    "        cnt += 1\n",
    "        cnt %= SEQ_LEN * BATCH_SIZE * 100\n",
    "    mean = sum_f / len(train_seq)\n",
    "    var = sum_sq_f / len(train_seq) - mean * mean\n",
    "    std = np.sqrt(var)\n",
    "    print len(train_seq), len(valid_seq)\n",
    "    print mean, std\n",
    "    return (train_seq, valid_seq), (mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139758 7200\n",
      "[-0.0047997167  0.043900186  11.352226] [ 0.051920877  0.39605346  3.7726]\n",
      "154131 0\n",
      "[ 0.0017989723  0.092735196  10.134581] [ 0.048207131  0.3890369  4.0389421]\n",
      "33808 0\n",
      "[-0.0084786136 -0.09063468  15.625128] [ 0.27152468  0.78744243  5.6971225]\n",
      "89205 0\n",
      "[-7.899939e-05  0.085713923  10.784245] [ 0.085205067  0.38865169  4.6383147]\n",
      "5614\n"
     ]
    }
   ],
   "source": [
    "(train_seq_main_1, valid_seq_1), (mean_1, std_1) = process_csv(filename=\"output/dataset5.csv\", val=5)\n",
    "(train_seq_main_2, valid_seq_2), (mean_2, std_2) = process_csv(filename=\"output/dataset6.csv\", val=0)\n",
    "(train_seq_main_3, valid_seq_3), (mean_3, std_3) = process_csv(filename=\"output/dataset7.csv\", val=0)\n",
    "(train_seq_main_4, valid_seq_4), (mean_4, std_4) = process_csv(filename=\"output/dataset8.csv\", val=0)\n",
    "\n",
    "mean, std = mean_1, std_1\n",
    "\n",
    "add_sets = [] # [\"output/dataset1.csv\", \"output/dataset2.csv\", \"output/dataset3.csv\", \"output/dataset4.csv\"]\n",
    "train_seq_add = map(read_csv, add_sets)\n",
    "\n",
    "train_seq = sum(train_seq_add, []) + train_seq_main_1 + train_seq_main_2 + train_seq_main_3 + train_seq_main_4\n",
    "valid_seq = (valid_seq_1 + valid_seq_2 + valid_seq_3 + valid_seq_4)\n",
    "\n",
    "test_seq = read_csv(\"challenge_2/exampleSubmissionInterpolatedFinal.csv\")\n",
    "\n",
    "print len(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_norm = lambda x: tf.contrib.layers.layer_norm(inputs=x, center=True, scale=True, activation_fn=None, trainable=True)\n",
    "\n",
    "def get_optimizer(loss, lrate):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=lrate)\n",
    "        gradvars = optimizer.compute_gradients(loss)\n",
    "        gradients, v = zip(*gradvars)\n",
    "        print [x.name for x in v]\n",
    "        gradients, _ = tf.clip_by_global_norm(gradients, 15.0)\n",
    "        return optimizer.apply_gradients(zip(gradients, v))\n",
    "\n",
    "def apply_vision_simple(image, keep_prob, batch_size, seq_len, scope=None, reuse=None):\n",
    "    video = tf.reshape(image, shape=[batch_size, LEFT_CONTEXT + seq_len, HEIGHT, WIDTH, CHANNELS])\n",
    "    with tf.variable_scope(scope, 'Vision', [image], reuse=reuse):\n",
    "            net = slim.convolution(video, num_outputs=64, kernel_size=[3,12,12], stride=[1,6,6], padding=\"VALID\")\n",
    "            net = tf.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "            aux1 = slim.fully_connected(tf.reshape(net[:, -seq_len:, :, :, :], [batch_size, seq_len, -1]), 128, activation_fn=None)\n",
    "            net = slim.convolution(net, num_outputs=64, kernel_size=[2,5,5], stride=[1,2,2], padding=\"VALID\")\n",
    "            net = tf.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "            aux2 = slim.fully_connected(tf.reshape(net[:, -seq_len:, :, :, :], [batch_size, seq_len, -1]), 128, activation_fn=None)\n",
    "            net = slim.convolution(net, num_outputs=64, kernel_size=[2,5,5], stride=[1,1,1], padding=\"VALID\")\n",
    "            net = tf.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "            aux3 = slim.fully_connected(tf.reshape(net[:, -seq_len:, :, :, :], [batch_size, seq_len, -1]), 128, activation_fn=None)\n",
    "            net = slim.convolution(net, num_outputs=64, kernel_size=[2,5,5], stride=[1,1,1], padding=\"VALID\")\n",
    "            net = tf.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "            print net # TODO must be batch_size x seq_len x ...\n",
    "            aux4 = slim.fully_connected(tf.reshape(net, [batch_size, seq_len, -1]), 128, activation_fn=None)\n",
    "            net = slim.fully_connected(tf.reshape(net, [batch_size, seq_len, -1]), 1024, activation_fn=tf.nn.relu)\n",
    "            net = tf.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "            net = slim.fully_connected(net, 512, activation_fn=tf.nn.relu)\n",
    "            net = tf.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "            net = slim.fully_connected(net, 256, activation_fn=tf.nn.relu)\n",
    "            net = tf.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "            net = slim.fully_connected(net, 128, activation_fn=None)\n",
    "            return layer_norm(tf.nn.elu(net + aux1 + aux2 + aux3 + aux4))\n",
    "\n",
    "class SamplingRNNCell(tf.nn.rnn_cell.RNNCell):\n",
    "  \"\"\"Simple sampling RNN cell.\"\"\"\n",
    "\n",
    "  def __init__(self, num_outputs, use_ground_truth, internal_cell, keep_prob):\n",
    "    \"\"\"\n",
    "    if use_ground_truth then don't sample\n",
    "    \"\"\"\n",
    "    self._num_outputs = num_outputs\n",
    "    self._use_ground_truth = use_ground_truth\n",
    "    self._internal_cell = internal_cell\n",
    "    self._keep_prob = keep_prob\n",
    "  \n",
    "  @property\n",
    "  def state_size(self):\n",
    "    return self._num_outputs, self._internal_cell.state_size # previous output and bottleneck state\n",
    "\n",
    "  @property\n",
    "  def output_size(self):\n",
    "    return self._num_outputs\n",
    "\n",
    "  def __call__(self, inputs, state, scope=None):\n",
    "    (visual_feats, current_ground_truth) = inputs\n",
    "    prev_output, prev_state_internal = state\n",
    "    # the following is just for a baseline\n",
    "    context = tf.concat(1, [prev_output, visual_feats])\n",
    "    new_output_internal, new_state_internal = internal_cell(context, prev_state_internal)\n",
    "    new_output = tf.contrib.layers.fully_connected(\n",
    "        inputs=tf.concat(1, [new_output_internal, prev_output, visual_feats]),\n",
    "        num_outputs=self._num_outputs,\n",
    "        activation_fn=None,\n",
    "        scope=\"OutputProjection\")\n",
    "    return new_output, (current_ground_truth if self._use_ground_truth else new_output, new_state_internal)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Vision/dropout_3/mul:0\", shape=(4, 10, 30, 43, 64), dtype=float32)\n",
      "[u'Vision/Conv/weights:0', u'Vision/Conv/biases:0', u'Vision/fully_connected/weights:0', u'Vision/fully_connected/biases:0', u'Vision/Conv_1/weights:0', u'Vision/Conv_1/biases:0', u'Vision/fully_connected_1/weights:0', u'Vision/fully_connected_1/biases:0', u'Vision/Conv_2/weights:0', u'Vision/Conv_2/biases:0', u'Vision/fully_connected_2/weights:0', u'Vision/fully_connected_2/biases:0', u'Vision/Conv_3/weights:0', u'Vision/Conv_3/biases:0', u'Vision/fully_connected_3/weights:0', u'Vision/fully_connected_3/biases:0', u'Vision/fully_connected_4/weights:0', u'Vision/fully_connected_4/biases:0', u'Vision/fully_connected_5/weights:0', u'Vision/fully_connected_5/biases:0', u'Vision/fully_connected_6/weights:0', u'Vision/fully_connected_6/biases:0', u'Vision/fully_connected_7/weights:0', u'Vision/fully_connected_7/biases:0', u'Vision/LayerNorm/beta:0', u'Vision/LayerNorm/gamma:0', u'controller_initial_state_0:0', u'controller_initial_state_1:0', u'controller_initial_state_2:0', u'predictor/RNN/LSTMCell/W_0:0', u'predictor/RNN/LSTMCell/B:0', u'predictor/RNN/LSTMCell/W_P_0:0', u'predictor/RNN/OutputProjection/weights:0', u'predictor/RNN/OutputProjection/biases:0']\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    #inputs  \n",
    "    learning_rate = tf.placeholder_with_default(input=1e-4, shape=())\n",
    "    keep_prob = tf.placeholder_with_default(input=1.0, shape=())\n",
    "    \n",
    "    inputs = tf.placeholder(shape=(BATCH_SIZE,LEFT_CONTEXT+SEQ_LEN), dtype=tf.string) # pathes to png files from the central camera\n",
    "    targets = tf.placeholder(shape=(BATCH_SIZE,SEQ_LEN,OUTPUT_DIM), dtype=tf.float32) # seq_len x batch_size x OUTPUT_DIM\n",
    "    targets_normalized = (targets - mean) / std\n",
    "    \n",
    "    input_images = tf.pack([tf.image.decode_png(tf.read_file(x))\n",
    "                            for x in tf.unpack(tf.reshape(inputs, shape=[(LEFT_CONTEXT+SEQ_LEN) * BATCH_SIZE]))])\n",
    "    input_images = -1.0 + 2.0 * tf.cast(input_images, tf.float32) / 255.0\n",
    "    input_images.set_shape([(LEFT_CONTEXT+SEQ_LEN) * BATCH_SIZE, HEIGHT, WIDTH, CHANNELS])\n",
    "    visual_conditions_reshaped = apply_vision_simple(image=input_images, keep_prob=keep_prob, \n",
    "                                                     batch_size=BATCH_SIZE, seq_len=SEQ_LEN)\n",
    "    visual_conditions = tf.reshape(visual_conditions_reshaped, [BATCH_SIZE, SEQ_LEN, -1])\n",
    "    visual_conditions = tf.nn.dropout(x=visual_conditions, keep_prob=keep_prob)\n",
    "    \n",
    "    rnn_inputs_with_ground_truth = (visual_conditions, targets_normalized)\n",
    "    rnn_inputs_autoregressive = (visual_conditions, tf.zeros(shape=(BATCH_SIZE, SEQ_LEN, OUTPUT_DIM), dtype=tf.float32))\n",
    "    \n",
    "    internal_cell = tf.nn.rnn_cell.LSTMCell(num_units=RNN_SIZE, num_proj=RNN_PROJ)\n",
    "    cell_with_ground_truth = SamplingRNNCell(num_outputs=OUTPUT_DIM, use_ground_truth=True, internal_cell=internal_cell, keep_prob=keep_prob)\n",
    "    cell_autoregressive = SamplingRNNCell(num_outputs=OUTPUT_DIM, use_ground_truth=False, internal_cell=internal_cell, keep_prob=keep_prob)\n",
    "    \n",
    "    def get_initial_state(complex_state_tuple_sizes):\n",
    "        flat_sizes = tf.nn.rnn_cell.nest.flatten(complex_state_tuple_sizes)\n",
    "        init_state_flat = [tf.tile(\n",
    "            multiples=[BATCH_SIZE, 1], \n",
    "            input=tf.get_variable(\"controller_initial_state_%d\" % i, initializer=tf.zeros_initializer, shape=([1, s]), dtype=tf.float32))\n",
    "         for i,s in enumerate(flat_sizes)]\n",
    "        init_state = tf.nn.rnn_cell.nest.pack_sequence_as(complex_state_tuple_sizes, init_state_flat)\n",
    "        return init_state\n",
    "    def deep_copy_initial_state(complex_state_tuple):\n",
    "        flat_state = tf.nn.rnn_cell.nest.flatten(complex_state_tuple)\n",
    "        flat_copy = [tf.identity(s) for s in flat_state]\n",
    "        deep_copy = tf.nn.rnn_cell.nest.pack_sequence_as(complex_state_tuple, flat_copy)\n",
    "        return deep_copy\n",
    "    \n",
    "    controller_initial_state_variables = get_initial_state(cell_autoregressive.state_size)\n",
    "    controller_initial_state_autoregressive = deep_copy_initial_state(controller_initial_state_variables)\n",
    "    controller_initial_state_gt = deep_copy_initial_state(controller_initial_state_variables)\n",
    "\n",
    "    with tf.variable_scope(\"predictor\"):\n",
    "        out_gt, controller_final_state_gt = tf.nn.dynamic_rnn(cell=cell_with_ground_truth, inputs=rnn_inputs_with_ground_truth, \n",
    "                          sequence_length=[SEQ_LEN]*BATCH_SIZE, initial_state=controller_initial_state_gt, dtype=tf.float32,\n",
    "                          swap_memory=True, time_major=False)\n",
    "    with tf.variable_scope(\"predictor\", reuse=True):\n",
    "        out_autoregressive, controller_final_state_autoregressive = tf.nn.dynamic_rnn(cell=cell_autoregressive, inputs=rnn_inputs_autoregressive, \n",
    "                          sequence_length=[SEQ_LEN]*BATCH_SIZE, initial_state=controller_initial_state_autoregressive, dtype=tf.float32,\n",
    "                          swap_memory=True, time_major=False)\n",
    "    \n",
    "    mse_gt = tf.reduce_mean(tf.squared_difference(out_gt, targets_normalized))\n",
    "    mse_autoregressive = tf.reduce_mean(tf.squared_difference(out_autoregressive, targets_normalized))\n",
    "    mse_autoregressive_steering = tf.reduce_mean(tf.squared_difference(out_autoregressive[:, :, 0], targets_normalized[:, :, 0]))\n",
    "    steering_predictions = (out_autoregressive[:, :, 0] * std[0]) + mean[0]\n",
    "    \n",
    "    total_loss = mse_autoregressive_steering # + 0.1 * (mse_gt + mse_autoregressive)\n",
    "    \n",
    "    optimizer = get_optimizer(total_loss, learning_rate)\n",
    "\n",
    "    tf.scalar_summary(\"MAIN TRAIN METRIC: rmse_autoregressive_steering\", tf.sqrt(mse_autoregressive_steering))\n",
    "    tf.scalar_summary(\"rmse_gt\", tf.sqrt(mse_gt))\n",
    "    tf.scalar_summary(\"rmse_autoregressive\", tf.sqrt(mse_autoregressive))\n",
    "    \n",
    "    summaries = tf.merge_all_summaries()\n",
    "    train_writer = tf.train.SummaryWriter('v3/train_summary', graph=graph)\n",
    "    valid_writer = tf.train.SummaryWriter('v3/valid_summary', graph=graph)\n",
    "    saver = tf.train.Saver(write_version=tf.train.SaverDef.V2)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Starting epoch 0\n",
      "Validation:\n",
      "180 / 180 1.50270079113\n",
      "\n",
      "Training\n",
      "10423 / 10423 1.8467856622\n",
      "Starting epoch 1\n",
      "Validation:\n",
      "180 / 180 0.874280615595\n",
      "SAVED at epoch 1 Validation unnormalized RMSE: 0.0453934155637\n",
      "\n",
      "Training\n",
      "10423 / 10423 1.77418961999\n",
      "Starting epoch 2\n",
      "Validation:\n",
      "180 / 180 0.811133286214\n",
      "SAVED at epoch 2 Validation unnormalized RMSE: 0.0421147514332\n",
      "\n",
      "Training\n",
      "10423 / 10423 1.68576334939\n",
      "Starting epoch 3\n",
      "Validation:\n",
      "180 / 180 0.800186080058\n",
      "SAVED at epoch 3 Validation unnormalized RMSE: 0.0415463624164\n",
      "\n",
      "Training\n",
      "10423 / 10423 1.54967948446\n",
      "Starting epoch 4\n",
      "Validation:\n",
      "180 / 180 0.878587929231\n",
      "Training\n",
      "10423 / 10423 1.32308876818\n",
      "Starting epoch 5\n",
      "Validation:\n",
      "180 / 180 0.845009498743\n",
      "Training\n",
      "10423 / 10423 1.11399653788\n",
      "Starting epoch 6\n",
      "Validation:\n",
      "180 / 180 0.723817861367\n",
      "SAVED at epoch 6 Validation unnormalized RMSE: 0.0375812570687\n",
      "\n",
      "Training\n",
      "10423 / 10423 0.966845877805\n",
      "Starting epoch 7\n",
      "Validation:\n",
      "180 / 180 0.630595047285\n",
      "SAVED at epoch 7 Validation unnormalized RMSE: 0.0327410471405\n",
      "\n",
      "Training\n",
      "10423 / 10423 0.877965091556\n",
      "Starting epoch 8\n",
      "Validation:\n",
      "180 / 180 0.571107767706\n",
      "SAVED at epoch 8 Validation unnormalized RMSE: 0.0296524153624\n",
      "\n",
      "Training\n",
      "10423 / 10423 0.828976471729\n",
      "Starting epoch 9\n",
      "Validation:\n",
      "180 / 180 0.572476876857\n",
      "Training\n",
      "10423 / 10423 0.759497823597\n",
      "Starting epoch 10\n",
      "Validation:\n",
      "180 / 180 0.537034595202\n",
      "SAVED at epoch 10 Validation unnormalized RMSE: 0.0278833064042\n",
      "\n",
      "Training\n",
      "10423 / 10423 0.715513620522\n",
      "Starting epoch 11\n",
      "Validation:\n",
      "180 / 180 0.535919350953\n",
      "SAVED at epoch 11 Validation unnormalized RMSE: 0.0278254019082\n",
      "\n",
      "Training\n",
      "10423 / 10423 0.692284031239\n",
      "Starting epoch 12\n",
      "Validation:\n",
      "180 / 180 0.526744747843\n",
      "SAVED at epoch 12 Validation unnormalized RMSE: 0.0273490485341\n",
      "\n",
      "Training\n",
      "10423 / 10423 0.637473502859\n",
      "Starting epoch 13\n",
      "Validation:\n",
      "180 / 180 0.569778657447\n",
      "Training\n",
      "10423 / 10423 0.630056599799\n",
      "Starting epoch 14\n",
      "Validation:\n",
      "180 / 180 0.556083854888\n",
      "Training\n",
      "10423 / 10423 0.598694345998\n",
      "Starting epoch 15\n",
      "Validation:\n",
      "180 / 180 0.664261112166\n",
      "Training\n",
      "10423 / 10423 0.6055241149\n",
      "Starting epoch 16\n",
      "Validation:\n",
      "180 / 180 0.564614931215\n",
      "Training\n",
      "10423 / 10423 0.554862793492\n",
      "Starting epoch 17\n",
      "Validation:\n",
      "180 / 180 0.571994301248\n",
      "Training\n",
      "10423 / 10423 0.550397694876\n",
      "Starting epoch 18\n",
      "Validation:\n",
      "180 / 180 0.512509056248\n",
      "SAVED at epoch 18 Validation unnormalized RMSE: 0.0266099188449\n",
      "\n",
      "Training\n",
      "10423 / 10423 0.521927586205\n",
      "Starting epoch 19\n",
      "Validation:\n",
      "180 / 180 0.566322113736\n",
      "Training\n",
      "10423 / 10423 0.503417398357\n",
      "Starting epoch 20\n",
      "Validation:\n",
      "180 / 180 0.514666041056\n",
      "Training\n",
      "10423 / 10423 0.501460116478\n",
      "Starting epoch 21\n",
      "Validation:\n",
      "180 / 180 0.511945166135\n",
      "SAVED at epoch 21 Validation unnormalized RMSE: 0.0265806410194\n",
      "\n",
      "Training\n",
      "10423 / 10423 0.513021702081\n",
      "Starting epoch 22\n",
      "Validation:\n",
      "180 / 180 0.532646328601\n",
      "Training\n",
      "10423 / 10423 0.508827489864\n",
      "Starting epoch 23\n",
      "Validation:\n",
      "180 / 180 0.522547064141\n",
      "Training\n",
      "10423 / 10423 0.478820788797\n",
      "Starting epoch 24\n",
      "Validation:\n",
      "180 / 180 0.534494332367\n",
      "Training\n",
      "10423 / 10423 0.474425909568\n",
      "Starting epoch 25\n",
      "Validation:\n",
      "180 / 180 0.498866417257\n",
      "SAVED at epoch 25 Validation unnormalized RMSE: 0.0259015811282\n",
      "\n",
      "Training\n",
      "10423 / 10423 0.464484439238\n",
      "Starting epoch 26\n",
      "Validation:\n",
      "180 / 180 0.499720075652\n",
      "Training\n",
      "10423 / 10423 0.430831271302\n",
      "Starting epoch 27\n",
      "Validation:\n",
      "180 / 180 0.49312012686\n",
      "SAVED at epoch 27 Validation unnormalized RMSE: 0.0256032285376\n",
      "\n",
      "Training\n",
      "10423 / 10423 0.443746631492\n",
      "Starting epoch 28\n",
      "Validation:\n",
      "180 / 180 0.494421852029\n",
      "Training\n",
      "10423 / 10423 0.430574294974\n",
      "Starting epoch 29\n",
      "Validation:\n",
      "180 / 180 0.511766195464\n",
      "Training\n",
      "10423 / 10423 0.412077643812\n",
      "Starting epoch 30\n",
      "Validation:\n",
      "180 / 180 0.471942753546\n",
      "SAVED at epoch 30 Validation unnormalized RMSE: 0.0245036808954\n",
      "\n",
      "Training\n",
      "10423 / 10423 0.410010802791\n",
      "Starting epoch 31\n",
      "Validation:\n",
      "180 / 180 0.524664799777\n",
      "Training\n",
      "10423 / 10423 0.436210523724\n",
      "Starting epoch 32\n",
      "Validation:\n",
      "180 / 180 0.496701844114\n",
      "Training\n",
      "10423 / 10423 0.419890532839\n",
      "Starting epoch 33\n",
      "Validation:\n",
      "180 / 180 0.492823388689\n",
      "Training\n",
      "10423 / 10423 0.410078737632\n",
      "Starting epoch 34\n",
      "Validation:\n",
      "180 / 180 0.507659482246\n",
      "Training\n",
      "10423 / 10423 0.404188217693\n",
      "Starting epoch 35\n",
      "Validation:\n",
      "180 / 180 0.493585766274\n",
      "Training\n",
      "10423 / 10423 0.39795016647\n",
      "Starting epoch 36\n",
      "Validation:\n",
      "180 / 180 0.48431130012\n",
      "Training\n",
      "10423 / 10423 0.410772317596\n",
      "Starting epoch 37\n",
      "Validation:\n",
      "180 / 180 0.512752157501\n",
      "Training\n",
      "10423 / 10423 0.362245632796\n",
      "Starting epoch 38\n",
      "Validation:\n",
      "180 / 180 0.49587093903\n",
      "Training\n",
      "10423 / 10423 0.408152859743\n",
      "Starting epoch 39\n",
      "Validation:\n",
      "180 / 180 0.491940354537\n",
      "Training\n",
      "383 / 10423 0.366074905751"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-aa089f05b863>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mdo_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-aa089f05b863>\u001b[0m in \u001b[0;36mdo_epoch\u001b[0;34m(session, sequences, mode)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkeep_prob\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mKEEP_PROB_TRAIN\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             summary, _, loss, controller_final_state_gt_cur, controller_final_state_autoregressive_cur =                 session.run([summaries, optimizer, mse_autoregressive_steering, controller_final_state_gt, controller_final_state_autoregressive],\n\u001b[0;32m---> 28\u001b[0;31m                            feed_dict = feed_dict)\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_train_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mglobal_train_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilia/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilia/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilia/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ilia/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilia/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1.0)\n",
    "\n",
    "checkpoint_dir = os.getcwd() + \"/v3\"\n",
    "\n",
    "global_train_step = 0\n",
    "global_valid_step = 0\n",
    "global_valid_predictions = {}\n",
    "\n",
    "KEEP_PROB_TRAIN = 0.25\n",
    "\n",
    "def do_epoch(session, sequences, mode):\n",
    "    global global_train_step, global_valid_step, global_valid_predictions\n",
    "    test_predictions = {}\n",
    "    batch_generator = BatchGenerator(sequence=sequences, seq_len=SEQ_LEN, batch_size=BATCH_SIZE)\n",
    "    total_num_steps = 1 + (batch_generator.indices[1] - 1) / SEQ_LEN\n",
    "    controller_final_state_gt_cur, controller_final_state_autoregressive_cur = None, None\n",
    "    acc_loss = np.float128(0.0)\n",
    "    for step in range(total_num_steps):\n",
    "        feed_inputs, feed_targets = batch_generator.next()\n",
    "        feed_dict = {inputs : feed_inputs, targets : feed_targets}\n",
    "        if controller_final_state_autoregressive_cur is not None:\n",
    "            feed_dict.update({controller_initial_state_autoregressive : controller_final_state_autoregressive_cur})\n",
    "        if controller_final_state_gt_cur is not None:\n",
    "            feed_dict.update({controller_final_state_gt : controller_final_state_gt_cur})\n",
    "        if mode == \"train\":\n",
    "            feed_dict.update({keep_prob : KEEP_PROB_TRAIN})\n",
    "            summary, _, loss, controller_final_state_gt_cur, controller_final_state_autoregressive_cur = \\\n",
    "                session.run([summaries, optimizer, mse_autoregressive_steering, controller_final_state_gt, controller_final_state_autoregressive],\n",
    "                           feed_dict = feed_dict)\n",
    "            train_writer.add_summary(summary, global_train_step)\n",
    "            global_train_step += 1\n",
    "        elif mode == \"valid\":\n",
    "            model_predictions, summary, loss, controller_final_state_autoregressive_cur = \\\n",
    "                session.run([steering_predictions, summaries, mse_autoregressive_steering, controller_final_state_autoregressive],\n",
    "                           feed_dict = feed_dict)\n",
    "            valid_writer.add_summary(summary, global_valid_step)\n",
    "            global_valid_step += 1\n",
    "            \n",
    "            feed_inputs = feed_inputs[:, LEFT_CONTEXT:].flatten()\n",
    "            steering_targets = feed_targets[:, :, 0].flatten()\n",
    "            model_predictions = model_predictions.flatten()\n",
    "            stats = np.stack([steering_targets, model_predictions, (steering_targets - model_predictions)**2])\n",
    "            for i, img in enumerate(feed_inputs):\n",
    "                global_valid_predictions[img] = stats[:, i]\n",
    "        elif mode == \"test\":\n",
    "            model_predictions, controller_final_state_autoregressive_cur = \\\n",
    "                session.run([steering_predictions, controller_final_state_autoregressive],\n",
    "                           feed_dict = feed_dict)           \n",
    "            feed_inputs = feed_inputs[:, LEFT_CONTEXT:].flatten()\n",
    "            model_predictions = model_predictions.flatten()\n",
    "            for i, img in enumerate(feed_inputs):\n",
    "                test_predictions[img] = model_predictions[i]\n",
    "        if mode != \"test\":\n",
    "            acc_loss += loss\n",
    "            print '\\r', step + 1, \"/\", total_num_steps, np.sqrt(acc_loss / (step+1)),\n",
    "    print\n",
    "    return np.sqrt(acc_loss / total_num_steps) if mode != \"test\" else test_predictions\n",
    "    \n",
    "\n",
    "NUM_EPOCHS=100\n",
    "\n",
    "best_validation_score = None\n",
    "with tf.Session(graph=graph, config=tf.ConfigProto(gpu_options=gpu_options)) as session:\n",
    "    session.run(tf.initialize_all_variables())\n",
    "    print 'Initialized'\n",
    "    ckpt = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    if ckpt:\n",
    "        print \"Restoring from\", ckpt\n",
    "        saver.restore(sess=session, save_path=ckpt)\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print \"Starting epoch %d\" % epoch\n",
    "        print \"Validation:\"\n",
    "        valid_score = do_epoch(session=session, sequences=valid_seq, mode=\"valid\")\n",
    "        if best_validation_score is None: \n",
    "            best_validation_score = valid_score\n",
    "            with open(\"v3/test-predictions-epoch%d\" % epoch, \"w\") as out:\n",
    "                test_predictions = do_epoch(session=session, sequences=test_seq, mode=\"test\")\n",
    "                print >> out, \"frame_id,steering_angle\"\n",
    "                for img, pred in test_predictions.items():\n",
    "                    img = img.replace(\"challenge_2/Test-final/center/\", \"\")\n",
    "                    print >> out, \"%s,%f\" % (img, pred)\n",
    "        if valid_score < best_validation_score:\n",
    "            saver.save(session, 'v3/checkpoint-sdc-ch2')\n",
    "            best_validation_score = valid_score\n",
    "            print '\\r', \"SAVED at epoch %d\" % epoch,\n",
    "            with open(\"v3/valid-predictions-epoch%d\" % epoch, \"w\") as out:\n",
    "                result = np.float128(0.0)\n",
    "                for img, stats in global_valid_predictions.items():\n",
    "                    print >> out, img, stats\n",
    "                    result += stats[-1]\n",
    "            print \"Validation unnormalized RMSE:\", np.sqrt(result / len(global_valid_predictions))\n",
    "            with open(\"v3/test-predictions-epoch%d\" % epoch, \"w\") as out:\n",
    "                test_predictions = do_epoch(session=session, sequences=test_seq, mode=\"test\")\n",
    "                print >> out, \"frame_id,steering_angle\"\n",
    "                for img, pred in test_predictions.items():\n",
    "                    img = img.replace(\"challenge_2/Test-final/center/\", \"\")\n",
    "                    print >> out, \"%s,%f\" % (img, pred)\n",
    "        if epoch != NUM_EPOCHS - 1:\n",
    "            print \"Training\"\n",
    "            do_epoch(session=session, sequences=train_seq, mode=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Restoring from /home/ilia/nn/sdc2/udacity-driving-reader/v3/checkpoint-sdc-ch2\n",
      "Starting epoch 0\n",
      "Validation:\n",
      "180 / 180 0.471942768313\n",
      "\n",
      "SAVED at epoch 0 Validation unnormalized RMSE: 0.0245036814524\n",
      "\n",
      "Training\n",
      "846 / 846 1.25031223664\n",
      "Starting epoch 1\n",
      "Validation:\n",
      "180 / 180 0.504185079126\n",
      "SAVED at epoch 1 Validation unnormalized RMSE: 0.0261777304285\n",
      "\n",
      "Training\n",
      "846 / 846 1.13577142797\n",
      "Starting epoch 2\n",
      "Validation:\n",
      "180 / 180 0.50290400244\n",
      "SAVED at epoch 2 Validation unnormalized RMSE: 0.0261112159347\n",
      "\n",
      "Training\n",
      "846 / 846 1.03962368301\n",
      "Starting epoch 3\n",
      "Validation:\n",
      "180 / 180 0.502557811881\n",
      "SAVED at epoch 3 Validation unnormalized RMSE: 0.0260932414149\n",
      "\n",
      "Training\n",
      "846 / 846 1.02208957899\n",
      "Starting epoch 4\n",
      "Validation:\n",
      "180 / 180 0.48331428505\n",
      "SAVED at epoch 4 Validation unnormalized RMSE: 0.0250941006176\n",
      "\n",
      "Training\n",
      "846 / 846 1.06320347588\n",
      "Starting epoch 5\n",
      "Validation:\n",
      "180 / 180 0.482416603701\n",
      "SAVED at epoch 5 Validation unnormalized RMSE: 0.0250474920664\n",
      "\n",
      "Training\n",
      "846 / 846 0.980025817164\n",
      "Starting epoch 6\n",
      "Validation:\n",
      "180 / 180 0.501465591367\n",
      "SAVED at epoch 6 Validation unnormalized RMSE: 0.0260365324179\n",
      "\n",
      "Training\n",
      "846 / 846 1.00019865775\n",
      "Starting epoch 7\n",
      "Validation:\n",
      "180 / 180 0.497336364377\n",
      "SAVED at epoch 7 Validation unnormalized RMSE: 0.0258221394254\n",
      "\n",
      "Training\n",
      "846 / 846 0.997520257902\n",
      "Starting epoch 8\n",
      "Validation:\n",
      "180 / 180 0.503239835025\n",
      "SAVED at epoch 8 Validation unnormalized RMSE: 0.0261286525624\n",
      "\n",
      "Training\n",
      "846 / 846 0.933070682653\n",
      "Starting epoch 9\n",
      "Validation:\n",
      "180 / 180 0.505246274925\n",
      "SAVED at epoch 9 Validation unnormalized RMSE: 0.0262328288223\n",
      "\n",
      "Training\n",
      "846 / 846 0.803238315153\n",
      "Starting epoch 10\n",
      "Validation:\n",
      "180 / 180 0.515212347406\n",
      "SAVED at epoch 10 Validation unnormalized RMSE: 0.0267502759202\n",
      "\n",
      "Training\n",
      "846 / 846 0.789357847392\n",
      "Starting epoch 11\n",
      "Validation:\n",
      "180 / 180 0.499365058653\n",
      "SAVED at epoch 11 Validation unnormalized RMSE: 0.0259274707612\n",
      "\n",
      "Training\n",
      "846 / 846 0.813514837815\n",
      "Starting epoch 12\n",
      "Validation:\n",
      "180 / 180 0.490078866276\n",
      "SAVED at epoch 12 Validation unnormalized RMSE: 0.0254453236179\n",
      "\n",
      "Training\n",
      "846 / 846 0.732097810287\n",
      "Starting epoch 13\n",
      "Validation:\n",
      "180 / 180 0.497980320838\n",
      "SAVED at epoch 13 Validation unnormalized RMSE: 0.0258555740278\n",
      "\n",
      "Training\n",
      "846 / 846 0.741533848278\n",
      "Starting epoch 14\n",
      "Validation:\n",
      "180 / 180 0.496386103054\n",
      "SAVED at epoch 14 Validation unnormalized RMSE: 0.0257728008842\n",
      "\n",
      "Training\n",
      "846 / 846 0.730568929841\n",
      "Starting epoch 15\n",
      "Validation:\n",
      "180 / 180 0.504041302034\n",
      "SAVED at epoch 15 Validation unnormalized RMSE: 0.0261702654943\n",
      "\n",
      "Training\n",
      "846 / 846 0.687613383339\n",
      "Starting epoch 16\n",
      "Validation:\n",
      "180 / 180 0.48549220879\n",
      "SAVED at epoch 16 Validation unnormalized RMSE: 0.0252071803487\n",
      "\n",
      "Training\n",
      "846 / 846 0.736857376122\n",
      "Starting epoch 17\n",
      "Validation:\n",
      "180 / 180 0.503545041609\n",
      "SAVED at epoch 17 Validation unnormalized RMSE: 0.0261444993031\n",
      "\n",
      "Training\n",
      "846 / 846 0.67799233145\n",
      "Starting epoch 18\n",
      "Validation:\n",
      "180 / 180 0.508750615657\n",
      "SAVED at epoch 18 Validation unnormalized RMSE: 0.0264147771823\n",
      "\n",
      "Training\n",
      "846 / 846 0.673661465709\n",
      "Starting epoch 19\n",
      "Validation:\n",
      "180 / 180 0.533667165345\n",
      "SAVED at epoch 19 Validation unnormalized RMSE: 0.0277084662741\n",
      "\n",
      "Training\n",
      "846 / 846 0.681423290172\n",
      "Starting epoch 20\n",
      "Validation:\n",
      "180 / 180 0.526147627663\n",
      "SAVED at epoch 20 Validation unnormalized RMSE: 0.0273180452931\n",
      "\n",
      "Training\n",
      "846 / 846 0.708430838184\n",
      "Starting epoch 21\n",
      "Validation:\n",
      "180 / 180 0.489662439194\n",
      "SAVED at epoch 21 Validation unnormalized RMSE: 0.0254237021309\n",
      "\n",
      "Training\n",
      "846 / 846 0.630650123049\n",
      "Starting epoch 22\n",
      "Validation:\n",
      "180 / 180 0.519056354214\n",
      "SAVED at epoch 22 Validation unnormalized RMSE: 0.0269498601831\n",
      "\n",
      "Training\n",
      "846 / 846 0.647933449251\n",
      "Starting epoch 23\n",
      "Validation:\n",
      "180 / 180 0.505264282206\n",
      "SAVED at epoch 23 Validation unnormalized RMSE: 0.0262337634817\n",
      "\n",
      "Training\n",
      "846 / 846 0.60827757725\n",
      "Starting epoch 24\n",
      "Validation:\n",
      "180 / 180 0.507585726165\n",
      "SAVED at epoch 24 Validation unnormalized RMSE: 0.0263542950888\n",
      "\n",
      "Training\n",
      "846 / 846 0.677382622357\n",
      "Starting epoch 25\n",
      "Validation:\n",
      "180 / 180 0.513298039969\n",
      "SAVED at epoch 25 Validation unnormalized RMSE: 0.0266508835149\n",
      "\n",
      "Training\n",
      "846 / 846 0.629408599691\n",
      "Starting epoch 26\n",
      "Validation:\n",
      "180 / 180 0.502899914779\n",
      "SAVED at epoch 26 Validation unnormalized RMSE: 0.0261110037324\n",
      "\n",
      "Training\n",
      "846 / 846 0.598177663592\n",
      "Starting epoch 27\n",
      "Validation:\n",
      "180 / 180 0.491570178214\n",
      "SAVED at epoch 27 Validation unnormalized RMSE: 0.0255227537428\n",
      "\n",
      "Training\n",
      "846 / 846 0.574112681105\n",
      "Starting epoch 28\n",
      "Validation:\n",
      "180 / 180 0.491042001363\n",
      "SAVED at epoch 28 Validation unnormalized RMSE: 0.0254953304775\n",
      "\n",
      "Training\n",
      "846 / 846 0.584223299642\n",
      "Starting epoch 29\n",
      "Validation:\n",
      "180 / 180 0.50882750867\n",
      "SAVED at epoch 29 Validation unnormalized RMSE: 0.0264187695773\n",
      "\n",
      "Training\n",
      "846 / 846 0.610597931816\n",
      "Starting epoch 30\n",
      "Validation:\n",
      "180 / 180 0.500152695239\n",
      "SAVED at epoch 30 Validation unnormalized RMSE: 0.0259683656548\n",
      "\n",
      "Training\n",
      "846 / 846 0.580205872479\n",
      "Starting epoch 31\n",
      "Validation:\n",
      "180 / 180 0.500480427905\n",
      "SAVED at epoch 31 Validation unnormalized RMSE: 0.0259853819472\n",
      "\n",
      "Training\n",
      "846 / 846 0.543174626291\n",
      "Starting epoch 32\n",
      "Validation:\n",
      "180 / 180 0.503911234762\n",
      "SAVED at epoch 32 Validation unnormalized RMSE: 0.0261635123785\n",
      "\n",
      "Training\n",
      "846 / 846 0.523748577504\n",
      "Starting epoch 33\n",
      "Validation:\n",
      "180 / 180 0.526072004109\n",
      "SAVED at epoch 33 Validation unnormalized RMSE: 0.0273141188148\n",
      "\n",
      "Training\n",
      "846 / 846 0.602637720358\n",
      "Starting epoch 34\n",
      "Validation:\n",
      "180 / 180 0.519535627163\n",
      "SAVED at epoch 34 Validation unnormalized RMSE: 0.0269747444172\n",
      "\n",
      "Training\n",
      "846 / 846 0.506337123195\n",
      "Starting epoch 35\n",
      "Validation:\n",
      "180 / 180 0.530281311548\n",
      "SAVED at epoch 35 Validation unnormalized RMSE: 0.0275326697402\n",
      "\n",
      "Training\n",
      "846 / 846 0.566494432676\n",
      "Starting epoch 36\n",
      "Validation:\n",
      "180 / 180 0.510745469638\n",
      "SAVED at epoch 36 Validation unnormalized RMSE: 0.0265183517073\n",
      "\n",
      "Training\n",
      "846 / 846 0.496866570462\n",
      "Starting epoch 37\n",
      "Validation:\n",
      "180 / 180 0.501386644128\n",
      "SAVED at epoch 37 Validation unnormalized RMSE: 0.0260324333742\n",
      "\n",
      "Training\n",
      "1 / 846 0.455563887643"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8c50b4893faa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mdo_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_seq_main_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-8c50b4893faa>\u001b[0m in \u001b[0;36mdo_epoch\u001b[0;34m(session, sequences, mode)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkeep_prob\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mKEEP_PROB_TRAIN\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             summary, _, loss, controller_final_state_gt_cur, controller_final_state_autoregressive_cur =                 session.run([summaries, optimizer, mse_autoregressive_steering, controller_final_state_gt, controller_final_state_autoregressive],\n\u001b[0;32m---> 28\u001b[0;31m                            feed_dict = feed_dict)\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_train_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mglobal_train_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilia/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilia/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilia/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ilia/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilia/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1.0)\n",
    "\n",
    "checkpoint_dir = os.getcwd() + \"/v3\"\n",
    "\n",
    "global_train_step = 0\n",
    "global_valid_step = 0\n",
    "global_valid_predictions = {}\n",
    "\n",
    "KEEP_PROB_TRAIN = 0.25\n",
    "\n",
    "def do_epoch(session, sequences, mode):\n",
    "    global global_train_step, global_valid_step, global_valid_predictions\n",
    "    test_predictions = {}\n",
    "    batch_generator = BatchGenerator(sequence=sequences, seq_len=SEQ_LEN, batch_size=BATCH_SIZE)\n",
    "    total_num_steps = 1 + (batch_generator.indices[1] - 1) / SEQ_LEN\n",
    "    controller_final_state_gt_cur, controller_final_state_autoregressive_cur = None, None\n",
    "    acc_loss = np.float128(0.0)\n",
    "    for step in range(total_num_steps):\n",
    "        feed_inputs, feed_targets = batch_generator.next()\n",
    "        feed_dict = {inputs : feed_inputs, targets : feed_targets}\n",
    "        if controller_final_state_autoregressive_cur is not None:\n",
    "            feed_dict.update({controller_initial_state_autoregressive : controller_final_state_autoregressive_cur})\n",
    "        if controller_final_state_gt_cur is not None:\n",
    "            feed_dict.update({controller_final_state_gt : controller_final_state_gt_cur})\n",
    "        if mode == \"train\":\n",
    "            feed_dict.update({keep_prob : KEEP_PROB_TRAIN})\n",
    "            summary, _, loss, controller_final_state_gt_cur, controller_final_state_autoregressive_cur = \\\n",
    "                session.run([summaries, optimizer, mse_autoregressive_steering, controller_final_state_gt, controller_final_state_autoregressive],\n",
    "                           feed_dict = feed_dict)\n",
    "            train_writer.add_summary(summary, global_train_step)\n",
    "            global_train_step += 1\n",
    "        elif mode == \"valid\":\n",
    "            model_predictions, summary, loss, controller_final_state_autoregressive_cur = \\\n",
    "                session.run([steering_predictions, summaries, mse_autoregressive_steering, controller_final_state_autoregressive],\n",
    "                           feed_dict = feed_dict)\n",
    "            valid_writer.add_summary(summary, global_valid_step)\n",
    "            global_valid_step += 1\n",
    "            \n",
    "            feed_inputs = feed_inputs[:, LEFT_CONTEXT:].flatten()\n",
    "            steering_targets = feed_targets[:, :, 0].flatten()\n",
    "            model_predictions = model_predictions.flatten()\n",
    "            stats = np.stack([steering_targets, model_predictions, (steering_targets - model_predictions)**2])\n",
    "            for i, img in enumerate(feed_inputs):\n",
    "                global_valid_predictions[img] = stats[:, i]\n",
    "        elif mode == \"test\":\n",
    "            model_predictions, controller_final_state_autoregressive_cur = \\\n",
    "                session.run([steering_predictions, controller_final_state_autoregressive],\n",
    "                           feed_dict = feed_dict)           \n",
    "            feed_inputs = feed_inputs[:, LEFT_CONTEXT:].flatten()\n",
    "            model_predictions = model_predictions.flatten()\n",
    "            for i, img in enumerate(feed_inputs):\n",
    "                test_predictions[img] = model_predictions[i]\n",
    "        if mode != \"test\":\n",
    "            acc_loss += loss\n",
    "            print '\\r', step + 1, \"/\", total_num_steps, np.sqrt(acc_loss / (step+1)),\n",
    "    print\n",
    "    return np.sqrt(acc_loss / total_num_steps) if mode != \"test\" else test_predictions\n",
    "    \n",
    "\n",
    "NUM_EPOCHS=100\n",
    "\n",
    "best_validation_score = None\n",
    "with tf.Session(graph=graph, config=tf.ConfigProto(gpu_options=gpu_options)) as session:\n",
    "    session.run(tf.initialize_all_variables())\n",
    "    print 'Initialized'\n",
    "    ckpt = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    if ckpt:\n",
    "        print \"Restoring from\", ckpt\n",
    "        saver.restore(sess=session, save_path=ckpt)\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print \"Starting epoch %d\" % epoch\n",
    "        print \"Validation:\"\n",
    "        valid_score = do_epoch(session=session, sequences=valid_seq, mode=\"valid\")\n",
    "        if best_validation_score is None: \n",
    "            best_validation_score = valid_score\n",
    "            with open(\"v3/FINETUNE-test-predictions-epoch%d\" % epoch, \"w\") as out:\n",
    "                test_predictions = do_epoch(session=session, sequences=test_seq, mode=\"test\")\n",
    "                print >> out, \"frame_id,steering_angle\"\n",
    "                for img, pred in test_predictions.items():\n",
    "                    img = img.replace(\"challenge_2/Test-final/center/\", \"\")\n",
    "                    print >> out, \"%s,%f\" % (img, pred)\n",
    "        if True or valid_score < best_validation_score:\n",
    "            saver.save(session, 'v3/FINETUNE-checkpoint-sdc-ch2')\n",
    "            best_validation_score = valid_score\n",
    "            print '\\r', \"SAVED at epoch %d\" % epoch,\n",
    "            with open(\"v3/FINETUNE-valid-predictions-epoch%d\" % epoch, \"w\") as out:\n",
    "                result = np.float128(0.0)\n",
    "                for img, stats in global_valid_predictions.items():\n",
    "                    print >> out, img, stats\n",
    "                    result += stats[-1]\n",
    "            print \"Validation unnormalized RMSE:\", np.sqrt(result / len(global_valid_predictions))\n",
    "            with open(\"v3/FINETUNE-test-predictions-epoch%d\" % epoch, \"w\") as out:\n",
    "                test_predictions = do_epoch(session=session, sequences=test_seq, mode=\"test\")\n",
    "                print >> out, \"frame_id,steering_angle\"\n",
    "                for img, pred in test_predictions.items():\n",
    "                    img = img.replace(\"challenge_2/Test-final/center/\", \"\")\n",
    "                    print >> out, \"%s,%f\" % (img, pred)\n",
    "        if epoch != NUM_EPOCHS - 1:\n",
    "            print \"Training\"\n",
    "            do_epoch(session=session, sequences=train_seq_main_3, mode=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Restoring from /home/ilia/nn/sdc2/udacity-driving-reader/v3/FINE_TUNE_2-checkpoint-sdc-ch2-epoch2\n",
      "Starting epoch 0\n",
      "Validation:\n",
      "180 / 180 0.493319772903\n",
      "\n",
      "SAVED at epoch 0 Validation unnormalized RMSE: 0.0256135944036\n",
      "\n",
      "Training\n",
      "10423 / 10423 0.357055723079\n",
      "Starting epoch 1\n",
      "Validation:\n",
      "180 / 180 0.506785779906\n",
      "SAVED at epoch 1 Validation unnormalized RMSE: 0.026312761425\n",
      "\n",
      "Training\n",
      "10423 / 10423 0.343080845742\n",
      "Starting epoch 2\n",
      "Validation:\n",
      "180 / 180 0.506069515761\n",
      "SAVED at epoch 2 Validation unnormalized RMSE: 0.0262755722093\n",
      "\n",
      "Training\n",
      "10423 / 10423 0.359480703785\n",
      "Starting epoch 3\n",
      "Validation:\n",
      "180 / 180 0.490330997847\n",
      "SAVED at epoch 3 Validation unnormalized RMSE: 0.0254584145878\n",
      "\n",
      "Training\n",
      "10423 / 10423 0.352017954507\n",
      "Starting epoch 4\n",
      "Validation:\n",
      "180 / 180 0.488294982346\n",
      "SAVED at epoch 4 Validation unnormalized RMSE: 0.0253527029018\n",
      "\n",
      "Training\n",
      "10423 / 10423 0.352547655156\n",
      "Starting epoch 5\n",
      "Validation:\n",
      "180 / 180 0.515736059348\n",
      "SAVED at epoch 5 Validation unnormalized RMSE: 0.0267774676803\n",
      "\n",
      "Training\n",
      "10423 / 10423 0.3680489967\n",
      "Starting epoch 6\n",
      "Validation:\n",
      "180 / 180 0.508152758268\n",
      "SAVED at epoch 6 Validation unnormalized RMSE: 0.0263837360796\n",
      "\n",
      "Training\n",
      "10423 / 10423 0.360647754039\n",
      "Starting epoch 7\n",
      "Validation:\n",
      "180 / 180 0.551537393421\n",
      "SAVED at epoch 7 Validation unnormalized RMSE: 0.0286363042289\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-69fb8542360e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Validation unnormalized RMSE:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_valid_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"v3/FINE_TUNE_2-test-predictions-epoch%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mtest_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0;34m>>\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"frame_id,steering_angle\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-69fb8542360e>\u001b[0m in \u001b[0;36mdo_epoch\u001b[0;34m(session, sequences, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             model_predictions, controller_final_state_autoregressive_cur =                 session.run([steering_predictions, controller_final_state_autoregressive],\n\u001b[0;32m---> 45\u001b[0;31m                            feed_dict = feed_dict)           \n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mfeed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLEFT_CONTEXT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mmodel_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilia/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilia/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilia/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ilia/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilia/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1.0)\n",
    "\n",
    "checkpoint_dir = os.getcwd() + \"/v3\"\n",
    "\n",
    "global_train_step = 0\n",
    "global_valid_step = 0\n",
    "global_valid_predictions = {}\n",
    "\n",
    "KEEP_PROB_TRAIN = 0.25\n",
    "\n",
    "def do_epoch(session, sequences, mode):\n",
    "    global global_train_step, global_valid_step, global_valid_predictions\n",
    "    test_predictions = {}\n",
    "    batch_generator = BatchGenerator(sequence=sequences, seq_len=SEQ_LEN, batch_size=BATCH_SIZE)\n",
    "    total_num_steps = 1 + (batch_generator.indices[1] - 1) / SEQ_LEN\n",
    "    controller_final_state_gt_cur, controller_final_state_autoregressive_cur = None, None\n",
    "    acc_loss = np.float128(0.0)\n",
    "    for step in range(total_num_steps):\n",
    "        feed_inputs, feed_targets = batch_generator.next()\n",
    "        feed_dict = {inputs : feed_inputs, targets : feed_targets}\n",
    "        if controller_final_state_autoregressive_cur is not None:\n",
    "            feed_dict.update({controller_initial_state_autoregressive : controller_final_state_autoregressive_cur})\n",
    "        if controller_final_state_gt_cur is not None:\n",
    "            feed_dict.update({controller_final_state_gt : controller_final_state_gt_cur})\n",
    "        if mode == \"train\":\n",
    "            feed_dict.update({keep_prob : KEEP_PROB_TRAIN})\n",
    "            summary, _, loss, controller_final_state_gt_cur, controller_final_state_autoregressive_cur = \\\n",
    "                session.run([summaries, optimizer, mse_autoregressive_steering, controller_final_state_gt, controller_final_state_autoregressive],\n",
    "                           feed_dict = feed_dict)\n",
    "            train_writer.add_summary(summary, global_train_step)\n",
    "            global_train_step += 1\n",
    "        elif mode == \"valid\":\n",
    "            model_predictions, summary, loss, controller_final_state_autoregressive_cur = \\\n",
    "                session.run([steering_predictions, summaries, mse_autoregressive_steering, controller_final_state_autoregressive],\n",
    "                           feed_dict = feed_dict)\n",
    "            valid_writer.add_summary(summary, global_valid_step)\n",
    "            global_valid_step += 1\n",
    "            \n",
    "            feed_inputs = feed_inputs[:, LEFT_CONTEXT:].flatten()\n",
    "            steering_targets = feed_targets[:, :, 0].flatten()\n",
    "            model_predictions = model_predictions.flatten()\n",
    "            stats = np.stack([steering_targets, model_predictions, (steering_targets - model_predictions)**2])\n",
    "            for i, img in enumerate(feed_inputs):\n",
    "                global_valid_predictions[img] = stats[:, i]\n",
    "        elif mode == \"test\":\n",
    "            model_predictions, controller_final_state_autoregressive_cur = \\\n",
    "                session.run([steering_predictions, controller_final_state_autoregressive],\n",
    "                           feed_dict = feed_dict)           \n",
    "            feed_inputs = feed_inputs[:, LEFT_CONTEXT:].flatten()\n",
    "            model_predictions = model_predictions.flatten()\n",
    "            for i, img in enumerate(feed_inputs):\n",
    "                test_predictions[img] = model_predictions[i]\n",
    "        if mode != \"test\":\n",
    "            acc_loss += loss\n",
    "            print '\\r', step + 1, \"/\", total_num_steps, np.sqrt(acc_loss / (step+1)),\n",
    "    print\n",
    "    return np.sqrt(acc_loss / total_num_steps) if mode != \"test\" else test_predictions\n",
    "    \n",
    "\n",
    "NUM_EPOCHS=100\n",
    "\n",
    "best_validation_score = None\n",
    "with tf.Session(graph=graph, config=tf.ConfigProto(gpu_options=gpu_options)) as session:\n",
    "    session.run(tf.initialize_all_variables())\n",
    "    print 'Initialized'\n",
    "    ckpt = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    if ckpt:\n",
    "        print \"Restoring from\", ckpt\n",
    "        saver.restore(sess=session, save_path=ckpt)\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print \"Starting epoch %d\" % epoch\n",
    "        print \"Validation:\"\n",
    "        valid_score = do_epoch(session=session, sequences=valid_seq, mode=\"valid\")\n",
    "        if best_validation_score is None: \n",
    "            best_validation_score = valid_score\n",
    "            with open(\"v3/FINE_TUNE_2-test-predictions-epoch%d\" % epoch, \"w\") as out:\n",
    "                test_predictions = do_epoch(session=session, sequences=test_seq, mode=\"test\")\n",
    "                print >> out, \"frame_id,steering_angle\"\n",
    "                for img, pred in test_predictions.items():\n",
    "                    img = img.replace(\"challenge_2/Test-final/center/\", \"\")\n",
    "                    print >> out, \"%s,%f\" % (img, pred)\n",
    "        if True or valid_score < best_validation_score:\n",
    "            saver.save(session, 'v3/FINE_TUNE_2-checkpoint-sdc-ch2-epoch%d' % epoch)\n",
    "            best_validation_score = valid_score\n",
    "            print '\\r', \"SAVED at epoch %d\" % epoch,\n",
    "            with open(\"v3/FINE_TUNE_2-valid-predictions-epoch%d\" % epoch, \"w\") as out:\n",
    "                result = np.float128(0.0)\n",
    "                for img, stats in global_valid_predictions.items():\n",
    "                    print >> out, img, stats\n",
    "                    result += stats[-1]\n",
    "            print \"Validation unnormalized RMSE:\", np.sqrt(result / len(global_valid_predictions))\n",
    "            with open(\"v3/FINE_TUNE_2-test-predictions-epoch%d\" % epoch, \"w\") as out:\n",
    "                test_predictions = do_epoch(session=session, sequences=test_seq, mode=\"test\")\n",
    "                print >> out, \"frame_id,steering_angle\"\n",
    "                for img, pred in test_predictions.items():\n",
    "                    img = img.replace(\"challenge_2/Test-final/center/\", \"\")\n",
    "                    print >> out, \"%s,%f\" % (img, pred)\n",
    "        if epoch != NUM_EPOCHS - 1:\n",
    "            print \"Training\"\n",
    "            do_epoch(session=session, sequences=train_seq, mode=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
