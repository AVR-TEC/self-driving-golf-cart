{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will explore vehicle detection with yolo\n",
    "The model will be trained with the COCO dataset for localization and also segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.merge import concatenate\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import imgaug as ia\n",
    "from tqdm import tqdm\n",
    "from imgaug import augmenters as iaa\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os, cv2\n",
    "import model as m\n",
    "from preprocessing import parse_annotation, BatchGenerator\n",
    "from utils import WeightReader, decode_netout, draw_boxes\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light' 'stop sign']\n",
    "\n",
    "IMAGE_H, IMAGE_W = 416, 416\n",
    "GRID_H, GRID_W  = 13 , 13\n",
    "BOX              = 5\n",
    "CLASS            = len(LABELS)\n",
    "CLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\n",
    "OBJ_THRESHOLD    = 0.5\n",
    "NMS_THRESHOLD    = 0.45\n",
    "ANCHORS          = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\n",
    "\n",
    "NO_OBJECT_SCALE  = 1.0\n",
    "OBJECT_SCALE     = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "CLASS_SCALE      = 1.0\n",
    "\n",
    "BATCH_SIZE       = 16\n",
    "WARM_UP_BATCHES  = 0\n",
    "TRUE_BOX_BUFFER  = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_path = './yolo.weights'                      \n",
    "# train_image_folder = '/home/ubunbu/dataset/COCO/train2017/'\n",
    "# train_annot_folder = '/home/ubunbu/dataset/COCO/annotations/'\n",
    "# valid_image_folder = '/home/ubunbu/dataset/COCO/val2017/'\n",
    "# valid_annot_folder = '/home/ubunbu/dataset/COCO/annotations/'\n",
    "\n",
    "train_image_folder = '/Volumes/Personal_Drive/Datasets/COCO/train2017/'\n",
    "train_annot_folder = '/Volumes/Personal_Drive/Datasets/COCO/annotations/'\n",
    "valid_image_folder = '/Volumes/Personal_Drive/Datasets/COCO/val2017/'\n",
    "valid_annot_folder = '/Volumes/Personal_Drive/Datasets/COCO/val_annotations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 416, 416, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                  (None, 416, 416, 32)  864         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "norm_1 (BatchNormalization)      (None, 416, 416, 32)  128         conv_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)        (None, 416, 416, 32)  0           norm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 208, 208, 32)  0           leaky_re_lu_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                  (None, 208, 208, 64)  18432       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "norm_2 (BatchNormalization)      (None, 208, 208, 64)  256         conv_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)        (None, 208, 208, 64)  0           norm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 104, 104, 64)  0           leaky_re_lu_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                  (None, 104, 104, 128) 73728       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "norm_3 (BatchNormalization)      (None, 104, 104, 128) 512         conv_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)        (None, 104, 104, 128) 0           norm_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                  (None, 104, 104, 64)  8192        leaky_re_lu_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "norm_4 (BatchNormalization)      (None, 104, 104, 64)  256         conv_4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)        (None, 104, 104, 64)  0           norm_4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                  (None, 104, 104, 128) 73728       leaky_re_lu_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "norm_5 (BatchNormalization)      (None, 104, 104, 128) 512         conv_5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)        (None, 104, 104, 128) 0           norm_5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 52, 52, 128)   0           leaky_re_lu_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv_6 (Conv2D)                  (None, 52, 52, 256)   294912      max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "norm_6 (BatchNormalization)      (None, 52, 52, 256)   1024        conv_6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)        (None, 52, 52, 256)   0           norm_6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv_7 (Conv2D)                  (None, 52, 52, 128)   32768       leaky_re_lu_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "norm_7 (BatchNormalization)      (None, 52, 52, 128)   512         conv_7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)        (None, 52, 52, 128)   0           norm_7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                  (None, 52, 52, 256)   294912      leaky_re_lu_7[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "norm_8 (BatchNormalization)      (None, 52, 52, 256)   1024        conv_8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)        (None, 52, 52, 256)   0           norm_8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, 26, 26, 256)   0           leaky_re_lu_8[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv_9 (Conv2D)                  (None, 26, 26, 512)   1179648     max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "norm_9 (BatchNormalization)      (None, 26, 26, 512)   2048        conv_9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)        (None, 26, 26, 512)   0           norm_9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv_10 (Conv2D)                 (None, 26, 26, 256)   131072      leaky_re_lu_9[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "norm_10 (BatchNormalization)     (None, 26, 26, 256)   1024        conv_10[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)       (None, 26, 26, 256)   0           norm_10[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_11 (Conv2D)                 (None, 26, 26, 512)   1179648     leaky_re_lu_10[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "norm_11 (BatchNormalization)     (None, 26, 26, 512)   2048        conv_11[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)       (None, 26, 26, 512)   0           norm_11[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_12 (Conv2D)                 (None, 26, 26, 256)   131072      leaky_re_lu_11[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "norm_12 (BatchNormalization)     (None, 26, 26, 256)   1024        conv_12[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)       (None, 26, 26, 256)   0           norm_12[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_13 (Conv2D)                 (None, 26, 26, 512)   1179648     leaky_re_lu_12[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "norm_13 (BatchNormalization)     (None, 26, 26, 512)   2048        conv_13[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)       (None, 26, 26, 512)   0           norm_13[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)   (None, 13, 13, 512)   0           leaky_re_lu_13[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv_14 (Conv2D)                 (None, 13, 13, 1024)  4718592     max_pooling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "norm_14 (BatchNormalization)     (None, 13, 13, 1024)  4096        conv_14[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)       (None, 13, 13, 1024)  0           norm_14[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_15 (Conv2D)                 (None, 13, 13, 512)   524288      leaky_re_lu_14[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "norm_15 (BatchNormalization)     (None, 13, 13, 512)   2048        conv_15[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)       (None, 13, 13, 512)   0           norm_15[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                 (None, 13, 13, 1024)  4718592     leaky_re_lu_15[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "norm_16 (BatchNormalization)     (None, 13, 13, 1024)  4096        conv_16[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)       (None, 13, 13, 1024)  0           norm_16[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_17 (Conv2D)                 (None, 13, 13, 512)   524288      leaky_re_lu_16[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "norm_17 (BatchNormalization)     (None, 13, 13, 512)   2048        conv_17[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)       (None, 13, 13, 512)   0           norm_17[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_18 (Conv2D)                 (None, 13, 13, 1024)  4718592     leaky_re_lu_17[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "norm_18 (BatchNormalization)     (None, 13, 13, 1024)  4096        conv_18[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)       (None, 13, 13, 1024)  0           norm_18[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_19 (Conv2D)                 (None, 13, 13, 1024)  9437184     leaky_re_lu_18[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "norm_19 (BatchNormalization)     (None, 13, 13, 1024)  4096        conv_19[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_21 (Conv2D)                 (None, 26, 26, 64)    32768       leaky_re_lu_13[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)       (None, 13, 13, 1024)  0           norm_19[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "norm_21 (BatchNormalization)     (None, 26, 26, 64)    256         conv_21[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_20 (Conv2D)                 (None, 13, 13, 1024)  9437184     leaky_re_lu_19[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)       (None, 26, 26, 64)    0           norm_21[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "norm_20 (BatchNormalization)     (None, 13, 13, 1024)  4096        conv_20[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 13, 13, 256)   0           leaky_re_lu_21[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)       (None, 13, 13, 1024)  0           norm_20[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 13, 13, 1280)  0           lambda_1[0][0]                   \n",
      "                                                                   leaky_re_lu_20[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv_22 (Conv2D)                 (None, 13, 13, 1024)  11796480    concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "norm_22 (BatchNormalization)     (None, 13, 13, 1024)  4096        conv_22[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)       (None, 13, 13, 1024)  0           norm_22[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_23 (Conv2D)                 (None, 13, 13, 75)    76875       leaky_re_lu_22[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)              (None, 13, 13, 5, 15) 0           conv_23[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 1, 1, 1, 50, 4 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)                (None, 13, 13, 5, 15) 0           reshape_1[0][0]                  \n",
      "                                                                   input_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 50,624,811\n",
      "Trainable params: 50,604,139\n",
      "Non-trainable params: 20,672\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = m.yolo_model(classes=CLASS,\n",
    "                    box=BOX,\n",
    "                    true_bbox_buffer=TRUE_BOX_BUFFER,\n",
    "                    image_h=IMAGE_H,\n",
    "                    image_w=IMAGE_W,\n",
    "                    grid_h=GRID_H,\n",
    "                    grid_w=GRID_W)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained weights\n",
    "originally provided by yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_reader = WeightReader(wt_path)\n",
    "\n",
    "weight_reader.reset()\n",
    "nb_conv = 23\n",
    "\n",
    "for i in range(1, nb_conv+1):\n",
    "    conv_layer = model.get_layer('conv_' + str(i))\n",
    "    \n",
    "    if i < nb_conv:\n",
    "        norm_layer = model.get_layer('norm_' + str(i))\n",
    "        \n",
    "        size = np.prod(norm_layer.get_weights()[0].shape)\n",
    "\n",
    "        beta  = weight_reader.read_bytes(size)\n",
    "        gamma = weight_reader.read_bytes(size)\n",
    "        mean  = weight_reader.read_bytes(size)\n",
    "        var   = weight_reader.read_bytes(size)\n",
    "\n",
    "        weights = norm_layer.set_weights([gamma, beta, mean, var])       \n",
    "        \n",
    "    if len(conv_layer.get_weights()) > 1:\n",
    "        bias   = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "        kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "        kernel = kernel.transpose([2,3,1,0])\n",
    "        conv_layer.set_weights([kernel, bias])\n",
    "    else:\n",
    "        kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "        kernel = kernel.transpose([2,3,1,0])\n",
    "        conv_layer.set_weights([kernel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer   = model.layers[-4] # the last convolutional layer\n",
    "weights = layer.get_weights()\n",
    "\n",
    "new_kernel = np.random.normal(size=weights[0].shape)/(GRID_H*GRID_W)\n",
    "new_bias   = np.random.normal(size=weights[1].shape)/(GRID_H*GRID_W)\n",
    "\n",
    "layer.set_weights([new_kernel, new_bias])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['captions_train2017.json',\n",
       " 'instances_train2017.json',\n",
       " 'person_keypoints_train2017.json']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(train_annot_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseError",
     "evalue": "not well-formed (invalid token): line 1, column 0 (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2910\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-14-77a0cea7871d>\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    train_imgs, seen_train_labels = parse_annotation(train_annot_folder, train_image_folder, labels=LABELS)\n",
      "  File \u001b[1;32m\"/Users/yongyangnie/Documents/Developer/ALVNS/vehicle_object_detection/yolo/preprocessing.py\"\u001b[0m, line \u001b[1;32m18\u001b[0m, in \u001b[1;35mparse_annotation\u001b[0m\n    tree = ET.parse(ann_dir + ann)\n",
      "  File \u001b[1;32m\"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/xml/etree/ElementTree.py\"\u001b[0m, line \u001b[1;32m1196\u001b[0m, in \u001b[1;35mparse\u001b[0m\n    tree.parse(source, parser)\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/xml/etree/ElementTree.py\"\u001b[0;36m, line \u001b[0;32m597\u001b[0;36m, in \u001b[0;35mparse\u001b[0;36m\u001b[0m\n\u001b[0;31m    self._root = parser._parse_whole(source)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32munknown\u001b[0m\n\u001b[0;31mParseError\u001b[0m\u001b[0;31m:\u001b[0m not well-formed (invalid token): line 1, column 0\n"
     ]
    }
   ],
   "source": [
    "train_imgs, seen_train_labels = parse_annotation(train_annot_folder, train_image_folder, labels=LABELS)\n",
    "### write parsed annotations to pickle for fast retrieval next time\n",
    "#with open('train_imgs', 'wb') as fp:\n",
    "#    pickle.dump(train_imgs, fp)\n",
    "\n",
    "### read saved pickle of parsed annotations\n",
    "#with open ('train_imgs', 'rb') as fp:\n",
    "#    train_imgs = pickle.load(fp)\n",
    "train_batch = BatchGenerator(train_imgs, generator_config)\n",
    "\n",
    "valid_imgs, seen_valid_labels = parse_annotation(valid_annot_folder, valid_image_folder, labels=LABELS)\n",
    "### write parsed annotations to pickle for fast retrieval next time\n",
    "#with open('valid_imgs', 'wb') as fp:\n",
    "#    pickle.dump(valid_imgs, fp)\n",
    "\n",
    "### read saved pickle of parsed annotations\n",
    "#with open ('valid_imgs', 'rb') as fp:\n",
    "#    valid_imgs = pickle.load(fp)\n",
    "valid_batch = BatchGenerator(valid_imgs, generator_config, jitter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.5e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "#optimizer = SGD(lr=1e-4, decay=0.0005, momentum=0.9)\n",
    "#optimizer = RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss=custom_loss, optimizer=optimizer)\n",
    "\n",
    "model.fit_generator(generator        = train_batch.get_generator(), \n",
    "                    steps_per_epoch  = train_batch.get_dateset_size(), \n",
    "                    epochs           = 100, \n",
    "                    verbose          = 1,\n",
    "                    validation_data  = valid_batch.get_generator(),\n",
    "                    validation_steps = valid_batch.get_dateset_size(),\n",
    "                    callbacks        = [early_stop, checkpoint, tensorboard], \n",
    "                    max_queue_size   = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing it on real images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"weights_coco.h5\")\n",
    "\n",
    "dummy_array = np.zeros((1,1,1,1,TRUE_BOX_BUFFER,4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
